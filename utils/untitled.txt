#         if self.logger:
#             self.logger.info(f'\nLoad tidy data from ... \n{self.datapath}')
#         self.data = pd.read_parquet(self.datapath, engine='auto', columns=None)
#         if self.logger:
#             self.logger.info(f'data.shape {self.data.shape}')
#             self.logger.info('data memory usage: {:.3f} GB'.format(sys.getsizeof(self.data)/1e9))
#         # print(data.groupby('SOURCE').agg({'CELL': 'nunique', 'DRUG': 'nunique', 'PUBCHEM': 'nunique'}).reset_index())

#         # Replace characters that are illegal for xgboost/lightgbm feature names
#         self.make_colnames_gbm_compatible()
        
#         # Keep subset of features
#         self.extract_subset_fea()

#         if args['tissue_type']:
#             # never tested!
#             self.data = self.data[self.data[''].isin([args['tissue_type']])].reset_index(drop=True)

#         # Subsample
#         if args['row_sample']:
#             row_sample = eval(args['row_sample'])
#             self.data = utils.subsample(df=self.data, v=row_sample, axis=0)
#             print('data.shape', self.data.shape)

#         if args['col_sample']:
#             col_sample = eval(args['col_sample'])
#             fea_data, other_data = self.split_fea_and_other_cols(self.data)
#             fea_data = utils.subsample(df=fea_data, v=col_sample, axis=1)
#             self.data = pd.concat([other_data, fea_data], axis=1)
#             print('data.shape', self.data.shape)

        # Extract test data based on sources
        # if self.logger:
        #    self.logger.info('\nExtract test sources ... {}'.format(args['test_sources']))
        
        # if args['test_sources']:    
        #     self.te_data = self.data[self.data['SOURCE'].isin(args['test_sources'])].reset_index(drop=True)
        #     if self.logger:
        #         self.logger.info(f'te_data.shape {self.te_data.shape}')
        #         self.logger.info('data memory usage: {:.3f} GB'.format(sys.getsizeof(self.te_data)/1e9))
        #         self.logger.info(self.te_data.groupby('SOURCE').agg({'CELL': 'nunique', 'DRUG': 'nunique'}).reset_index())
        # else:
        #     self.te_data = None
        #     if self.logger:
        #         self.logger.info('No test data.')

        # Extract train data based on  sources
        # if self.logger:
        #     self.logger.info('\nExtract train sources ... {}'.format(args['train_sources']))
        # self.tr_data = self.data[self.data['SOURCE'].isin(args['train_sources'])].reset_index(drop=True)
        # if self.logger:
        #     self.logger.info(f'tr_data.shape {tr_data.shape}')
        #     self.logger.info('tr_data memory usage: {:.3f} GB'.format(sys.getsizeof(self.tr_data)/1e9))
        #     self.logger.info(self.tr_data.groupby('SOURCE').agg({'CELL': 'nunique', 'DRUG': 'nunique'}).reset_index())

        # Scale features
        # if args['scaler'] is not None:
        #     if args['scaler'] == 'stnd':
        #         scaler = StandardScaler()
        #     elif args['scaler'] == 'minmax':
        #         scaler = MinMaxScaler()
        #     elif args['scaler'] == 'rbst':
        #         scaler = RobustScaler()

            # Scale train data
        #     fea_data, other_data = self.split_fea_and_other_cols(self.tr_data)
        #     fea_data, cat_data = self.get_num_and_cat_cols(fea_data)
        #     colnames = fea_data.columns
        #     fea_data = pd.DataFrame( scaler.fit_transform(fea_data), columns=colnames ).astype(np.float32)
        #     self.tr_data = pd.concat([other_data, cat_data, fea_data], axis=1)
        #     self.xdata = pd.concat([cat_data, fea_data], axis=1)

            # Scale test data
        #     if self.te_data is not None:
        #         fea_data, other_data = self.split_fea_and_other_cols(self.te_data)
        #         fea_data, cat_data = self.get_num_and_cat_cols(fea_data)
        #         colnames = fea_data.columns
        #         fea_data = pd.DataFrame( scaler.transform(fea_data), columns=colnames ).astype(np.float32)
        #         self.te_data = pd.concat([other_data, cat_data, fea_data], axis=1)
        #         xte = pd.concat([cat_data, fea_data], axis=1)

        # Assign type to categoricals
        # cat_cols = data.select_dtypes(include='object').columns.tolist()
        # data[cat_cols] = data[cat_cols].astype('category', ordered=False)

        # Filter out AUC>1
        # print('\nFilter some AUC outliers (>1)')
        # print('data.shape', data.shape)
        # data = data[[False if x>1.0 else True for x in data[target_name]]].reset_index(drop=True)
        # print('data.shape', data.shape)

        # if 'dlb' in args['other_features']:
        #     if logger:
        #         logger.info('\nAdd drug labels to features ...')
        #     # print(data['DRUG'].value_counts())

        #     # http://queirozf.com/entries/one-hot-encoding-a-feature-on-a-pandas-dataframe-an-example
        #     # One-hot encoder
        #     dlb = pd.get_dummies(data=data[['DRUG']], prefix=fea_prfx_dict['dlb'],
        #                         dummy_na=False).reset_index(drop=True)

        #     # Label encoder
        #     # dlb = data[['DRUG']].astype('category', ordered=False).reset_index(drop=True)
        #     # print(dlb.dtype)

        #     # Concat drug labels and other features
        #     data = pd.concat([dlb, data], axis=1).reset_index(drop=True)
        #     if logger:
        #         logger.info(f'dlb.shape {dlb.shape}')
        #         logger.info(f'data.shape {data.shape}')

        # if 'rna_clusters' in args['other_features']:
        #     # TODO
        #     pass