{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = Path('../../data/yitan/Data')\n",
    "ccl_folds_dir = Path('../../data/yitan/CCL_10Fold_Partition')\n",
    "pdm_folds_dir = Path('../../data/yitan/PDM_10Fold_Partition')\n",
    "fea_data_name = 'CCL_PDM_TransferLearningData_rmFactor_0.0_ddNorm_std.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un-pickle files\n",
    "import _pickle as cp\n",
    "\n",
    "pkl_file = open(datadir/fea_data_name, 'rb')\n",
    "res = cp.load(pkl_file)\n",
    "ccl = cp.load(pkl_file)\n",
    "drg = cp.load(pkl_file)\n",
    "pkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res  (708662, 5)\n",
      "ccl  (1430, 4582)\n",
      "drg  (1402, 4392)\n"
     ]
    }
   ],
   "source": [
    "print('res ', res.shape)\n",
    "print('ccl ', ccl.shape)\n",
    "print('drg ', drg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>ccl_name</th>\n",
       "      <th>ctrpDrugID</th>\n",
       "      <th>area_under_curve</th>\n",
       "      <th>groupID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCLE</td>\n",
       "      <td>CCL_61</td>\n",
       "      <td>Drug_11</td>\n",
       "      <td>0.7153</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCLE</td>\n",
       "      <td>CCL_61</td>\n",
       "      <td>Drug_1</td>\n",
       "      <td>0.9579</td>\n",
       "      <td>0.9164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SOURCE ccl_name ctrpDrugID  area_under_curve  groupID\n",
       "0   CCLE   CCL_61    Drug_11            0.7153   0.0000\n",
       "1   CCLE   CCL_61     Drug_1            0.9579   0.9164"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geneGE_AARS</th>\n",
       "      <th>geneGE_ABCB6</th>\n",
       "      <th>geneGE_ABCC5</th>\n",
       "      <th>geneGE_ABCF1</th>\n",
       "      <th>geneGE_ABCF3</th>\n",
       "      <th>geneGE_ABHD4</th>\n",
       "      <th>geneGE_ABHD6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CCL_1</th>\n",
       "      <td>-0.125161</td>\n",
       "      <td>-0.400237</td>\n",
       "      <td>-0.960208</td>\n",
       "      <td>0.575207</td>\n",
       "      <td>-0.468406</td>\n",
       "      <td>-0.136257</td>\n",
       "      <td>0.083319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCL_10</th>\n",
       "      <td>-0.217106</td>\n",
       "      <td>0.354776</td>\n",
       "      <td>-1.164841</td>\n",
       "      <td>0.328071</td>\n",
       "      <td>-0.735267</td>\n",
       "      <td>0.232990</td>\n",
       "      <td>-0.174979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        geneGE_AARS  geneGE_ABCB6  geneGE_ABCC5  geneGE_ABCF1  geneGE_ABCF3  \\\n",
       "CCL_1     -0.125161     -0.400237     -0.960208      0.575207     -0.468406   \n",
       "CCL_10    -0.217106      0.354776     -1.164841      0.328071     -0.735267   \n",
       "\n",
       "        geneGE_ABHD4  geneGE_ABHD6  \n",
       "CCL_1      -0.136257      0.083319  \n",
       "CCL_10      0.232990     -0.174979  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DD_MW|num</th>\n",
       "      <th>DD_AMW|num</th>\n",
       "      <th>DD_Sv|num</th>\n",
       "      <th>DD_Se|num</th>\n",
       "      <th>DD_Sp|num</th>\n",
       "      <th>DD_Si|num</th>\n",
       "      <th>DD_Mv|num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Drug_1</th>\n",
       "      <td>0.123446</td>\n",
       "      <td>0.526234</td>\n",
       "      <td>-0.072180</td>\n",
       "      <td>-0.088861</td>\n",
       "      <td>-0.058460</td>\n",
       "      <td>-0.083100</td>\n",
       "      <td>-0.009539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drug_10</th>\n",
       "      <td>0.053188</td>\n",
       "      <td>1.966100</td>\n",
       "      <td>-0.333843</td>\n",
       "      <td>-0.379081</td>\n",
       "      <td>-0.359584</td>\n",
       "      <td>-0.398841</td>\n",
       "      <td>1.172374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DD_MW|num  DD_AMW|num  DD_Sv|num  DD_Se|num  DD_Sp|num  DD_Si|num  \\\n",
       "Drug_1    0.123446    0.526234  -0.072180  -0.088861  -0.058460  -0.083100   \n",
       "Drug_10   0.053188    1.966100  -0.333843  -0.379081  -0.359584  -0.398841   \n",
       "\n",
       "         DD_Mv|num  \n",
       "Drug_1   -0.009539  \n",
       "Drug_10   1.172374  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(res[:2])\n",
    "display(ccl.iloc[:2, :7])\n",
    "display(drg.iloc[:2, :7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>ccl_name</th>\n",
       "      <th>ctrpDrugID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCLE</td>\n",
       "      <td>474</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CTRP</td>\n",
       "      <td>812</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GDSC</td>\n",
       "      <td>670</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCI60</td>\n",
       "      <td>59</td>\n",
       "      <td>987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PDM</td>\n",
       "      <td>473</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gCSI</td>\n",
       "      <td>357</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SOURCE  ccl_name  ctrpDrugID\n",
       "0   CCLE       474          24\n",
       "1   CTRP       812         494\n",
       "2   GDSC       670         238\n",
       "3  NCI60        59         987\n",
       "4    PDM       473          18\n",
       "5   gCSI       357          16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.groupby('SOURCE').agg({'ccl_name': 'nunique', 'ctrpDrugID': 'nunique'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.949566358842101e-18\n",
      "1.000699790062981\n",
      "0.1652929135842889\n",
      "0.5961096596718728\n"
     ]
    }
   ],
   "source": [
    "# Check normalization\n",
    "print(ccl.mean(axis=0).mean())\n",
    "print(ccl.var(axis=0).mean())\n",
    "\n",
    "print(drg.mean(axis=0).mean())\n",
    "print(drg.var(axis=0).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>src</th>\n",
       "      <th>ccl_name</th>\n",
       "      <th>ctrpDrugID</th>\n",
       "      <th>auc</th>\n",
       "      <th>groupID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CCLE</td>\n",
       "      <td>CCL_61</td>\n",
       "      <td>Drug_11</td>\n",
       "      <td>0.7153</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CCLE</td>\n",
       "      <td>CCL_61</td>\n",
       "      <td>Drug_1</td>\n",
       "      <td>0.9579</td>\n",
       "      <td>0.9164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx   src ccl_name ctrpDrugID     auc  groupID\n",
       "0    0  CCLE   CCL_61    Drug_11  0.7153   0.0000\n",
       "1    1  CCLE   CCL_61     Drug_1  0.9579   0.9164"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bring in the row index\n",
    "res = res.reset_index()\n",
    "res = res.rename(columns={'index': 'idx', 'SOURCE': 'src', 'area_under_curve': 'auc'})\n",
    "res[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale\n",
    "def scale_df(df):\n",
    "    index = df.index\n",
    "    columns = df.columns\n",
    "    scaler = StandardScaler()\n",
    "    df = pd.DataFrame( scaler.fit_transform(df), index=index, columns=columns ).astype(np.float32)\n",
    "    return df\n",
    "\n",
    "# ccl = scale_df(ccl)\n",
    "# drg = scale_df(drg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Where are the genomic features coming from?\n",
    "Gene expression is coming from CCLE or NCI60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ccl_ = cell.reset_index().rename(columns={'index': 'ccl_name'})\n",
    "\n",
    "# display(ccl_.iloc[:2, :5])\n",
    "# display(res[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# aa = pd.merge(ccl_[['ccl_name']], res[['SOURCE', 'ccl_name']], on='ccl_name', how='inner')\n",
    "# # aa = aa.drop_duplicates().reset_index(drop=True)\n",
    "# print(aa.shape)\n",
    "# print(aa['SOURCE'].value_counts())\n",
    "\n",
    "# bb = aa[aa['ccl_name']=='CCL_1']['SOURCE'].value_counts()\n",
    "# print(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# del ccl_, aa, bb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# What features are available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def cnt_fea(df, fea_sep='_', verbose=True):\n",
    "#     \"\"\" Count the number of features per feature type. \"\"\"\n",
    "#     dct = {}\n",
    "#     unq_prfx = df.columns.map(lambda x: x.split(fea_sep)[0]).unique() # unique feature prefixes\n",
    "#     for prfx in unq_prfx:\n",
    "#         fea_type_cols = [c for c in df.columns if (c.split(fea_sep)[0]) in prfx] # all fea names of specific type\n",
    "#         dct[prfx] = len(fea_type_cols)\n",
    "#     if verbose: print(dct)\n",
    "#     return dct\n",
    "\n",
    "# cnt_fea(ccl, fea_sep='_');\n",
    "# cnt_fea(drg, fea_sep='_');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def extract_subset_fea(df, fea_list, fea_sep='_'):\n",
    "#     \"\"\" Extract features based feature prefix name. \"\"\"\n",
    "#     fea = [c for c in df.columns if (c.split(fea_sep)[0]) in fea_list]\n",
    "#     df = df[fea]\n",
    "#     return df\n",
    "\n",
    "# tmp = extract_subset_fea(ccl, fea_list=['geneGE', 'c2cpMaxGE'], fea_sep='_')\n",
    "# cnt_fea(tmp, fea_sep='_', verbose=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def extract_unq_fea_dfs(df, fea_sep='_'):\n",
    "#     \"\"\" Generate dict where each element is a separate df with unique feature type. \"\"\"\n",
    "#     dct_fea_prfx = cnt_fea(df, fea_sep=fea_sep)\n",
    "#     dct_dfs = {}\n",
    "#     for k in dct_fea_prfx.keys():\n",
    "#         fea_type_cols = [c for c in df.columns if (c.split(fea_sep)[0]) in k]\n",
    "#         dct_dfs[k] = df[fea_type_cols]\n",
    "#     return dct_dfs\n",
    "\n",
    "# # Cell dfs\n",
    "# ccl_dct = extract_unq_fea_dfs(ccl, fea_sep='_')\n",
    "# display(ccl_dct['geneGE'].shape)\n",
    "# display(ccl_dct['c2cpMaxGE'].shape)\n",
    "# display(ccl_dct['c2cpMinGE'].shape)\n",
    "\n",
    "# # Drug dfs\n",
    "# drg_dct = extract_unq_fea_dfs(drg, fea_sep='_')\n",
    "# display(drg_dct['DD'].shape)\n",
    "# display(drg_dct['ECFP'].shape)\n",
    "# display(drg_dct['PFP'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge features and target into a single df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnt_fea(df, fea_sep='_', verbose=True):\n",
    "    \"\"\" Count the number of features per feature type. \"\"\"\n",
    "    dct = {}\n",
    "    unq_prfx = df.columns.map(lambda x: x.split(fea_sep)[0]).unique() # unique feature prefixes\n",
    "    for prfx in unq_prfx:\n",
    "        fea_type_cols = [c for c in df.columns if (c.split(fea_sep)[0]) in prfx] # all fea names of specific type\n",
    "        dct[prfx] = len(fea_type_cols)\n",
    "    if verbose: print(dct)\n",
    "    return dct\n",
    "\n",
    "def extract_subset_fea(df, fea_list, fea_sep='_'):\n",
    "    \"\"\" Extract features based feature prefix name. \"\"\"\n",
    "    fea = [c for c in df.columns if (c.split(fea_sep)[0]) in fea_list]\n",
    "    df = df[fea]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Args\n",
    "src = 'GDSC'\n",
    "fold = 0\n",
    "ccl_fea_list = ['geneGE']\n",
    "drg_fea_list = ['DD']\n",
    "fea_sep = '_'\n",
    "# fea_float_dtype = fea_float_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train portion: 0.80\n",
      "Full dataset: (708662, 6)\n",
      "Only GDSC:  (135568, 6)\n",
      "\n",
      "res_tr.shape: (108481, 6)\n",
      "res_vl.shape: (13507, 6)\n",
      "\n",
      "Extract fea types ...\n",
      "{'geneGE': 1927, 'c2cpMaxGE': 1328, 'c2cpMinGE': 1327}\n",
      "{'geneGE': 1927}\n",
      "{'DD': 2344, 'ECFP': 1024, 'PFP': 1024}\n",
      "{'DD': 2344}\n"
     ]
    }
   ],
   "source": [
    "res_df_ = res.copy()\n",
    "ccl_df_ = ccl.copy()\n",
    "drg_df_ = drg.copy()\n",
    "\n",
    "# Get lists of ccl names based on src and fold\n",
    "ids_path = ccl_folds_dir/f'{src}/cv_{fold}' # 'TestList.txt'\n",
    "tr_ids_list = pd.read_csv(ids_path/'TrainList.txt', header=None).squeeze().values\n",
    "vl_ids_list = pd.read_csv(ids_path/'ValList.txt', header=None).squeeze().values\n",
    "te_ids_list = pd.read_csv(ids_path/'TestList.txt', header=None).squeeze().values\n",
    "\n",
    "# Show how much is left for train, val, and test\n",
    "tr_sz, vl_sz, te_sz = len(tr_ids_list), len(vl_ids_list), len(te_ids_list)\n",
    "sz = tr_sz + vl_sz + te_sz\n",
    "print(f'Train portion: {tr_sz/sz:.2f}')\n",
    "\n",
    "# Retain specific source\n",
    "print('Full dataset:', res_df_.shape)\n",
    "res_df_ = res_df_[ res_df_['src'].isin([src]) ]\n",
    "print(f'Only {src}: ', res_df_.shape)\n",
    "\n",
    "# Create res dfs for train and val\n",
    "res_tr = res_df_[ res_df_['ccl_name'].isin( tr_ids_list ) ]\n",
    "res_vl = res_df_[ res_df_['ccl_name'].isin( vl_ids_list ) ]\n",
    "print('\\nres_tr.shape:', res_tr.shape)\n",
    "print('res_vl.shape:', res_vl.shape)\n",
    "\n",
    "# Extract specific types of features\n",
    "print('\\nExtract fea types ...')\n",
    "cnt_fea(ccl_df_);\n",
    "ccl_df_ = extract_subset_fea(df=ccl_df_, fea_list=ccl_fea_list, fea_sep=fea_sep)\n",
    "cnt_fea(ccl_df_);\n",
    "\n",
    "cnt_fea(drg_df_);\n",
    "drg_df_ = extract_subset_fea(df=drg_df_, fea_list=drg_fea_list, fea_sep=fea_sep)\n",
    "cnt_fea(drg_df_);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring the labels in, in order to merge on\n",
    "ccl_df_ = ccl_df_.reset_index().rename(columns={'index': 'ccl_name'})\n",
    "drg_df_ = drg_df_.reset_index().rename(columns={'index': 'ctrpDrugID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrg_tr.shape: (108481, 4277)\n",
      "mrg_vl.shape: (13507, 4277)\n"
     ]
    }
   ],
   "source": [
    "# Merge data\n",
    "def merge_dfs(res_df, ccl_df, drg_df):\n",
    "    \"\"\" Merge the following dfs: response, ccl fea, drug fea \"\"\"\n",
    "    mrg_df = pd.merge(res_df, ccl_df, on='ccl_name', how='inner')\n",
    "    mrg_df = pd.merge(mrg_df, drg_df, on='ctrpDrugID', how='inner')\n",
    "    return mrg_df\n",
    "\n",
    "mrg_tr = merge_dfs(res_tr, ccl_df_, drg_df_)\n",
    "mrg_vl = merge_dfs(res_vl, ccl_df_, drg_df_)\n",
    "\n",
    "print('\\nMerge ...')\n",
    "print('mrg_tr.shape:', mrg_tr.shape)\n",
    "print('mrg_vl.shape:', mrg_vl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtr.shape: (108481, 4271)\n",
      "xvl.shape: (13507, 4271)\n"
     ]
    }
   ],
   "source": [
    "# Extract x and y\n",
    "xtr = extract_subset_fea(mrg_tr, fea_list = ccl_fea_list + drg_fea_list, fea_sep=fea_sep)\n",
    "ytr = mrg_tr[['auc']]\n",
    "\n",
    "xvl = extract_subset_fea(mrg_vl, fea_list = ccl_fea_list + drg_fea_list, fea_sep=fea_sep)\n",
    "yvl = mrg_vl[['auc']]\n",
    "\n",
    "print('\\nExtract x and y ...')\n",
    "print('xtr.shape:', xtr.shape)\n",
    "print('xvl.shape:', xvl.shape)\n",
    "print('ytr.shape:', ytr.shape)\n",
    "print('yvl.shape:', yvl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump to file\n",
    "xtr.to_parquet(datadir/f'{src.lower()}_xtr.parquet')\n",
    "ytr.to_parquet(datadir/f'{src.lower()}_ytr.parquet')\n",
    "\n",
    "xvl.to_parquet(datadir/f'{src.lower()}_xvl.parquet')\n",
    "yvl.to_parquet(datadir/f'{src.lower()}_yvl.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708662, 6)\n",
      "(1430, 4582)\n",
      "(1402, 4392)\n"
     ]
    }
   ],
   "source": [
    "print(res.shape)\n",
    "print(ccl.shape)\n",
    "print(drg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "#  Test code of pytroch dataset\n",
    "# ------------------------------\n",
    "\n",
    "# res_df = res.copy()\n",
    "# drg_df = drg.copy()\n",
    "# ccl_df = ccl.copy()\n",
    "\n",
    "# tr_ph = 'train'\n",
    "# fold = 0\n",
    "# src = 'CCLE'\n",
    "# ccl_fea_list = ['geneGE']\n",
    "# drg_fea_list = ['DD']\n",
    "\n",
    "# res_df = res_df[ res_df['SOURCE'].isin([src]) ]\n",
    "# drg_df = extract_subset_fea(drg_df, drg_fea_list, fea_sep='_')\n",
    "# ccl_df = extract_subset_fea(ccl_df, ccl_fea_list, fea_sep='_')\n",
    "\n",
    "# path = ccl_folds_dir/f'{src}/cv_{fold}'\n",
    "\n",
    "# res_arr = res_df.values\n",
    "# drg_fea_dct = {idx: row.values for idx, row in drg_df.iterrows()}\n",
    "# ccl_fea_dct = {idx: row.values for idx, row in ccl_df.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Dataset_Raw(Dataset):\n",
    "    # discuss.pytorch.org/t/data-processing-as-a-batch-way/14154\n",
    "    # github.com/utkuozbulak/pytorch-custom-dataset-examples#incorporating-pandas\n",
    "    # nbviewer.jupyter.org/github/FraPochetti/KagglePlaygrounds/blob/master/NYC%20Taxi%20Fares%20Prediction.ipynb\n",
    "    def __init__(self,\n",
    "                 res_df: pd.DataFrame,\n",
    "                 ccl_df: pd.DataFrame,\n",
    "                 drg_df: pd.DataFrame,\n",
    "                 ccl_folds_dir: str,\n",
    "                 src: str,\n",
    "                 fold: int,\n",
    "                 tr_ph: str,\n",
    "                 ccl_fea_list: list=None,\n",
    "                 drg_fea_list: list=None,\n",
    "                 fea_sep: str='_',\n",
    "                 fea_float_dtype: type=torch.float32,\n",
    "                 # target_float_dtype: type=torch.float64,\n",
    "                 # drg_dsc_preproc: str=None,  # TODO\n",
    "                 # ccl_rna_preproc: str=None,  # TODO\n",
    "                 verbose: bool=True):\n",
    "        \"\"\" \n",
    "        Define pytorch dataset for drug response prediction.\n",
    "        Args:\n",
    "            res_df (pd.DataFrame) : drug response df\n",
    "            ccl_df (pd.DataFrame) : cell feature df\n",
    "            drg_df (pd.DataFrame) : drug feature df\n",
    "            ccl_folds_dir (str) : folder path that contains cv patitions in text files\n",
    "            src (str) : source name\n",
    "            fold (int) : fold index\n",
    "            tr_ph (str) : training phase ('tr', 'vl', 'te')\n",
    "            ccl_fea_list (list) : list of prefixes of cell features to retain\n",
    "            drg_fea_list (list) : list of prefixes of drug features to retain\n",
    "            fea_sep (str) : separator of feature prefix that indicates type and feature name\n",
    "            fea_float_dtype (type) : float precision for features\n",
    "            drg_dsc_preproc (str) : TODO: not implemented\n",
    "            cell_rna_preproc (str) : TODO: not implemented\n",
    "            verbose : bool=True\n",
    "        \"\"\"\n",
    "        # ============================================\n",
    "        # Initialize\n",
    "        # ============================================\n",
    "        self.ccl_folds_dir = ccl_folds_dir\n",
    "        self.src = src\n",
    "        self.fold = fold\n",
    "        self.tr_ph = tr_ph.lower()\n",
    "        self.ccl_fea_list = ccl_fea_list\n",
    "        self.drg_fea_list = drg_fea_list\n",
    "        self.fea_sep = fea_sep\n",
    "        self.fea_float_dtype = fea_float_dtype\n",
    "\n",
    "        # ============================================\n",
    "        # Get the ccl names\n",
    "        # ============================================\n",
    "        if self.tr_ph in ['tr', 'train', 'training']:\n",
    "            self.ids_fname = 'TrainList.txt'\n",
    "        elif self.tr_ph in ['vl', 'val', 'validation']:\n",
    "            self.ids_fname = 'ValList.txt'\n",
    "        elif self.tr_ph in ['te', 'test', 'testing']:\n",
    "            self.ids_fname = 'TestList.txt'\n",
    "        else:\n",
    "            raise ValueError('Must specify valid `tr_ph` argument.')\n",
    "            \n",
    "        self.ids_path = self.ccl_folds_dir/f'{self.src}/cv_{self.fold}'/self.ids_fname # 'TestList.txt'        \n",
    "        self.ids_list = pd.read_csv(self.ids_path, header=None).squeeze().values\n",
    "        \n",
    "        # ============================================\n",
    "        # Load dfs\n",
    "        # ============================================\n",
    "        res_df = res_df[ res_df['src'].isin([src]) ]  # extract responses of specific source\n",
    "        self.res_df = res_df[ res_df['ccl_name'].isin( self.ids_list ) ]  # extract responses of specific ccl samples\n",
    "        \n",
    "        # Extract specific types of features\n",
    "        self.ccl_df = ccl_df if self.ccl_fea_list is None else self.extract_subset_fea(ccl_df, fea_list=self.ccl_fea_list, fea_sep=self.fea_sep)\n",
    "        self.drg_df = drg_df if self.drg_fea_list is None else self.extract_subset_fea(drg_df, fea_list=self.drg_fea_list, fea_sep=self.fea_sep)\n",
    "        \n",
    "        # ============================================\n",
    "        # Public attributes\n",
    "        # ============================================\n",
    "        self.cells = self.res_df['ccl_name'].unique().tolist()    # unique cells\n",
    "        self.drugs = self.res_df['ctrpDrugID'].unique().tolist()  # unique drugs\n",
    "        self.num_records = len(self.res_df)\n",
    "        self.ccl_dim = self.ccl_df.shape[1]\n",
    "        self.drg_dim = self.drg_df.shape[1]\n",
    "        \n",
    "        self.ccl_fea_cnt = self.cnt_fea(self.ccl_df, fea_sep=self.fea_sep, verbose=False)\n",
    "        self.drg_fea_cnt = self.cnt_fea(self.drg_df, fea_sep=self.fea_sep, verbose=False)\n",
    "        \n",
    "        # ============================================\n",
    "        # Convert dfs to arrays and dict for faster access\n",
    "        # ============================================\n",
    "        # self.res_arr = self.res_df.values\n",
    "        # self.ccl_fea_dct = {idx: row.values for idx, row in self.ccl_df.iterrows()}\n",
    "        # self.drg_fea_dct = {idx: row.values for idx, row in self.drg_df.iterrows()}\n",
    "        # TODO: does the values must be pytorch tensors??\n",
    "        self.res_arr = self.res_df.values\n",
    "        self.ccl_fea_dct = {idx: torch.tensor(row.values, dtype=fea_float_dtype) for idx, row in self.ccl_df.iterrows()}\n",
    "        self.drg_fea_dct = {idx: torch.tensor(row.values, dtype=fea_float_dtype) for idx, row in self.drg_df.iterrows()}\n",
    "\n",
    "        # ============================================\n",
    "        # Summary\n",
    "        # ============================================\n",
    "        if verbose:\n",
    "            print('=' * 80)\n",
    "            print(f'Data source: {self.src}')\n",
    "            print(f'Phase: {tr_ph}')\n",
    "            print(f'Data points: {self.num_records}')\n",
    "            print(f'Unique cells: {len(self.cells)}')\n",
    "            print(f'Unique drugs: {len(self.drugs)}')\n",
    "            print(f'ccl_df.shape: {self.ccl_df.shape}')\n",
    "            print(f'drg_df.shape: {self.drg_df.shape}')\n",
    "            print(f'Cell features: {self.ccl_fea_cnt}')\n",
    "            print(f'Drug features: {self.drg_fea_cnt}')\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.res_arr)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" \n",
    "        Ref: github.com/xduan7/UnoPytorch/blob/master/utils/datasets/drug_resp_dataset.py\n",
    "        Look for __getitem__ in DrugRespDataset\n",
    "        \n",
    "        res indices: [idx, src, ccl_name, ctrpDrugID, auc, groupID]\n",
    "        \"\"\"\n",
    "        res = self.res_arr[index]\n",
    "        \n",
    "        idx = res[0]\n",
    "        src = res[1]\n",
    "        ccl_id = res[2]\n",
    "        drg_id = res[3]\n",
    "        auc = res[4]\n",
    "        grp_id = res[5]\n",
    "        \n",
    "        ccl_fea = self.ccl_fea_dct[ccl_id]\n",
    "        drg_fea = self.drg_fea_dct[drg_id]\n",
    "        \n",
    "        # Cast values\n",
    "        # ccl_fea = ccl_fea.astype(np.float32)\n",
    "        # drg_fea = drg_fea.astype(np.float32)\n",
    "        \n",
    "        # return ccl_fea, drg_fea, auc\n",
    "        return idx, src, ccl_id, drg_id, auc, ccl_fea, drg_fea\n",
    "    \n",
    "    \n",
    "    def extract_subset_fea(self, df, fea_list, fea_sep='_'):\n",
    "        \"\"\" Extract features based feature prefix name. \"\"\"\n",
    "        fea = [c for c in df.columns if (c.split(fea_sep)[0]) in fea_list]\n",
    "        df = df[fea]\n",
    "        return df    \n",
    "    \n",
    "    \n",
    "    def cnt_fea(self, df, fea_sep='_', verbose=True):\n",
    "        \"\"\" Count the number of features per feature type. \"\"\"\n",
    "        dct = {}\n",
    "        unq_prfx = df.columns.map(lambda x: x.split(fea_sep)[0]).unique() # unique feature prefixes\n",
    "        for prfx in unq_prfx:\n",
    "            fea_type_cols = [c for c in df.columns if (c.split(fea_sep)[0]) in prfx] # all fea names of specific type\n",
    "            dct[prfx] = len(fea_type_cols)\n",
    "        if verbose: print(dct)\n",
    "        return dct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Data source: GDSC\n",
      "Phase: tr\n",
      "Data points: 108481\n",
      "Unique cells: 536\n",
      "Unique drugs: 238\n",
      "ccl_df.shape: (1430, 1927)\n",
      "drg_df.shape: (1402, 2344)\n",
      "Cell features: {'geneGE': 1927}\n",
      "Drug features: {'DD': 2344}\n",
      "================================================================================\n",
      "Data source: GDSC\n",
      "Phase: vl\n",
      "Data points: 13507\n",
      "Unique cells: 67\n",
      "Unique drugs: 238\n",
      "ccl_df.shape: (1430, 1927)\n",
      "drg_df.shape: (1402, 2344)\n",
      "Cell features: {'geneGE': 1927}\n",
      "Drug features: {'DD': 2344}\n",
      "================================================================================\n",
      "Data source: GDSC\n",
      "Phase: te\n",
      "Data points: 13580\n",
      "Unique cells: 67\n",
      "Unique drugs: 238\n",
      "ccl_df.shape: (1430, 1927)\n",
      "drg_df.shape: (1402, 2344)\n",
      "Cell features: {'geneGE': 1927}\n",
      "Drug features: {'DD': 2344}\n"
     ]
    }
   ],
   "source": [
    "ccl_fea_list = ['geneGE']\n",
    "drg_fea_list = ['DD']\n",
    "\n",
    "ds_kwargs = {\n",
    "    'res_df': res,\n",
    "    'ccl_df': ccl,\n",
    "    'drg_df': drg,\n",
    "    'ccl_folds_dir': ccl_folds_dir,\n",
    "    'src': 'GDSC',\n",
    "    'ccl_fea_list': ccl_fea_list,\n",
    "    'drg_fea_list': drg_fea_list,\n",
    "    'fea_sep': '_'}\n",
    "\n",
    "fold = 0\n",
    "tr_ds = Dataset_Raw(tr_ph='tr', fold=fold, **ds_kwargs)\n",
    "vl_ds = Dataset_Raw(tr_ph='vl', fold=fold, **ds_kwargs)\n",
    "te_ds = Dataset_Raw(tr_ph='te', fold=fold, **ds_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data loaders\n",
    "Data loaders for training/validation in github.com/xduan7/UnoPytorch/blob/master/uno_pytorch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_jobs = 4\n",
    "tr_loader_kwargs = {'batch_size': batch_size, 'shuffle': True,  'num_workers': n_jobs}\n",
    "vl_loader_kwargs = {'batch_size': 4*batch_size, 'shuffle': False, 'num_workers': n_jobs}\n",
    "te_loader_kwargs = {'batch_size': 4*batch_size, 'shuffle': False, 'num_workers': n_jobs}\n",
    "\n",
    "tr_loader = DataLoader(tr_ds, **tr_loader_kwargs)\n",
    "vl_loader = DataLoader(vl_ds, **vl_loader_kwargs)\n",
    "te_loader = DataLoader(te_ds, **te_loader_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### --- Test --- generate a single batch from dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ret = next(iter(tr_loader))  # (idx, SOURCE, ccl_id, drg_id, auc, ccl_fea, drg_fea)\n",
    "\n",
    "# idx = ret[0]\n",
    "# src = ret[1]\n",
    "# cell_id = ret[2]\n",
    "# drug_id = ret[3]\n",
    "# auc = ret[4]\n",
    "# ccl_fea = ret[5]\n",
    "# drg_fea = ret[6]\n",
    "\n",
    "# print('ccl_fea:', ccl_fea.shape)\n",
    "# print('drg_fea:', drg_fea.shape)\n",
    "# display(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # print( sum(tr_ds.res_df['ccl_name']==ret[2][0]) )\n",
    "# # print( sum(tr_ds.res_df['ctrpDrugID']==ret[3][0]) )\n",
    "# # sum( (tr_ds.res_df['ccl_name']==ret[2][0]) & (tr_ds.res_df['ctrpDrugID']==ret[3][0]) )\n",
    "\n",
    "# tr_ds.res_df.loc[ret[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Now, look at the merged dataset\n",
    "# tmp = tr_df[tr_df['idx']==ret[0].item()]\n",
    "# display(tmp.iloc[:, :10])\n",
    "\n",
    "# ge = extract_subset_fea(df=tmp, fea_list=ccl_fea_list, fea_sep='_')\n",
    "# dd = extract_subset_fea(df=tmp, fea_list=drg_fea_list, fea_sep='_')\n",
    "\n",
    "# print('ge.shape', ge.shape)\n",
    "# print('dd.shape', dd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define NN\n",
    "Look at \"Constructing and initializing neural networks\" in github.com/xduan7/UnoPytorch/blob/master/uno_pytorch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_device(model):\n",
    "    return str(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init_linear(m: nn.Module):\n",
    "    # Weight initialization\n",
    "    \"\"\"\n",
    "    Pytorch initializes the layers by default (e.g., Linear uses kaiming_uniform_)\n",
    "    www.deeplearningwizard.com/deep_learning/boosting_models_pytorch/weight_initialization_activation_functions/\n",
    "    stackoverflow.com/questions/49433936/how-to-initialize-weights-in-pytorch\n",
    "    github.com/xduan7/UnoPytorch/blob/master/networks/initialization/weight_init.py\n",
    "    \"\"\"\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define NN_REG (Top6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_Reg_Merged(nn.Module):\n",
    "    \"\"\" ... \"\"\"\n",
    "    def __init__(self,\n",
    "                 ccl_dim: int,\n",
    "                 drg_dim: int,\n",
    "                 dr_rate: float=0.2,\n",
    "                 # hidden_activation: str=None,\n",
    "                 # output_activation: str=None\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.ccl_dim = ccl_dim\n",
    "        self.drg_dim = drg_dim\n",
    "        self.dr_rate = dr_rate        \n",
    "        \n",
    "        self.fc1 = nn.Linear(self.ccl_dim + self.drg_dim, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 500)\n",
    "        self.fc3 = nn.Linear(500, 250)\n",
    "        self.fc4 = nn.Linear(250, 60)\n",
    "        self.fc5 = nn.Linear(60, 1)\n",
    "        self.dropout = nn.Dropout(dr_rate)\n",
    "        \n",
    "        \n",
    "    def forward(self, ccl_fea, drg_fea):\n",
    "        x = torch.cat((ccl_fea, drg_fea), dim=1)\n",
    "        \n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = self.dropout(F.relu(self.fc4(x)))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define DrugRespNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_Reg_Raw(nn.Module):\n",
    "    def __init__(self,\n",
    "                 ccl_dim: int,\n",
    "                 drg_dim: int,\n",
    "                 dr_rate: float=0.2,\n",
    "                 hidden_activation: str=None,\n",
    "                 output_activation: str=None):\n",
    "        super().__init__()\n",
    "        self.ccl_dim = ccl_dim\n",
    "        self.drg_dim = drg_dim\n",
    "        self.dr_rate = dr_rate\n",
    "        # self.hidden_activation = hidden_activation\n",
    "        # self.output_activation = output_activation\n",
    "\n",
    "        # self.layers = [self.ccl_dim+self.drg_dim, 1000, 1000, 500, 250, 125, 60, 30, 1]\n",
    "        # self.net = nn.ModuleList([ nn.Linear(self.layers[i], self.layers[i+1]) for i in range(len(self.layers)-1) ])\n",
    "        # self.net.apply(weight_init_linear)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.ccl_dim + self.drg_dim, 1000)\n",
    "        self.bn1 = nn.BatchNorm1d(1000)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1000, 1000)\n",
    "        self.bn2 = nn.BatchNorm1d(1000)\n",
    "        \n",
    "        self.fc3 = nn.Linear(1000, 500)\n",
    "        self.bn3 = nn.BatchNorm1d(500)\n",
    "        \n",
    "        self.fc4 = nn.Linear(500, 250)\n",
    "        self.bn4 = nn.BatchNorm1d(250)\n",
    "        \n",
    "        self.fc5 = nn.Linear(250, 125)\n",
    "        self.bn5 = nn.BatchNorm1d(125)\n",
    "        \n",
    "        self.fc6 = nn.Linear(125, 60)\n",
    "        self.bn6 = nn.BatchNorm1d(60)\n",
    "\n",
    "        self.fc7 = nn.Linear(60, 30)\n",
    "        self.bn7 = nn.BatchNorm1d(30)\n",
    "        \n",
    "        self.fc8 = nn.Linear(30, 1)\n",
    "\n",
    "         \n",
    "    def forward(self, ccl_fea, drg_fea):\n",
    "        # pytorch.org/docs/stable/nn.html?highlight=batch_norm#torch.nn.BatchNorm1d\n",
    "        # pytorch.org/docs/stable/nn.html?highlight=batch_norm\n",
    "        # Input\n",
    "        x = torch.cat((ccl_fea, drg_fea), dim=1)\n",
    "        \n",
    "        # Expanded\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dr_rate, training=self.training)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dr_rate, training=self.training)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dr_rate, training=self.training)\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dr_rate, training=self.training)\n",
    "\n",
    "        x = self.fc6(x)\n",
    "        x = self.bn6(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dr_rate, training=self.training)\n",
    "\n",
    "        x = self.fc7(x)\n",
    "        x = self.bn7(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dr_rate, training=self.training)\n",
    "\n",
    "        x = self.fc8(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "#         # Packed\n",
    "#         x = F.relu(self.bn1(self.fc1(x)))\n",
    "#         x = F.dropout(F.relu(self.bn2(self.fc2(x))), p=self.dr_rate, training=self.training)\n",
    "#         x = F.dropout(F.relu(self.bn3(self.fc3(x))), p=self.dr_rate, training=self.training)\n",
    "#         x = F.dropout(F.relu(self.bn4(self.fc4(x))), p=self.dr_rate, training=self.training)\n",
    "#         x = F.dropout(F.relu(self.bn5(self.fc5(x))), p=self.dr_rate, training=self.training)\n",
    "#         x = F.dropout(F.relu(self.bn6(self.fc6(x))), p=self.dr_rate, training=self.training)\n",
    "#         x = F.dropout(F.relu(self.bn7(self.fc7(x))), p=self.dr_rate, training=self.training)\n",
    "#         x = F.relu(self.fc8(x))\n",
    "            \n",
    "#         # Coded\n",
    "#         for i, layer in enumerate(self.net):\n",
    "#             if i == 0:\n",
    "#                 # input layer\n",
    "#                 x = layer(x)\n",
    "#                 x = F.batch_norm(x, training=self.training)\n",
    "#                 x = F.relu(x)\n",
    "                \n",
    "#             elif i == (len(self.layers) - 1):\n",
    "#                 # output layer\n",
    "#                 x = layer(x)\n",
    "#                 x = F.relu(x) # TODO: should this be mse\n",
    "\n",
    "#             else:\n",
    "#                 # hidden layers\n",
    "#                 x = layer(x)\n",
    "#                 x = F.batch_norm(x, training=self.training)\n",
    "#                 x = F.relu(x)\n",
    "#                 x = F.dropout(x, p=self.dr_rate, training=self.training)\n",
    "                        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_available:   True\n",
      "device_name:    GeForce RTX 2080 Ti\n",
      "device_count:   4\n",
      "current_device: 0\n"
     ]
    }
   ],
   "source": [
    "# pytorch.org/docs/stable/cuda.html\n",
    "# towardsdatascience.com/speed-up-your-algorithms-part-1-pytorch-56d8a4ae7051\n",
    "print('is_available:  ', torch.cuda.is_available())\n",
    "print('device_name:   ', torch.cuda.get_device_name(0))\n",
    "print('device_count:  ', torch.cuda.device_count())\n",
    "print('current_device:', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which device to use\n",
    "device_name = 'cuda:3'\n",
    "device = torch.device(device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network and move it to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN_REG(\n",
      "  (fc1): Linear(in_features=4271, out_features=1000, bias=True)\n",
      "  (fc2): Linear(in_features=1000, out_features=500, bias=True)\n",
      "  (fc3): Linear(in_features=500, out_features=250, bias=True)\n",
      "  (fc4): Linear(in_features=250, out_features=60, bias=True)\n",
      "  (fc5): Linear(in_features=60, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_name = 'nn_reg_merged' # drug_resp_net\n",
    "\n",
    "if model_name == 'nn_reg_merged':\n",
    "    model = NN_Reg_Merged(\n",
    "        ccl_dim = tr_ds.ccl_dim,\n",
    "        drg_dim = tr_ds.drg_dim,\n",
    "        dr_rate = 0.2)\n",
    "\n",
    "elif model_name == 'nn_reg_raw':\n",
    "    model = NN_Reg_Raw(\n",
    "        ccl_dim = tr_ds.ccl_dim,\n",
    "        drg_dim = tr_ds.drg_dim,\n",
    "        dr_rate = 0.2)\n",
    "\n",
    "# Init weights\n",
    "model.apply(weight_init_linear)\n",
    "\n",
    "# Model to gpu/cpu device\n",
    "model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n",
      "current_device: 0\n"
     ]
    }
   ],
   "source": [
    "# Query device where the model is\n",
    "print(get_model_device(model))\n",
    "print('current_device:', torch.cuda.current_device()) # why current device is 0??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### --- Test --- forward pass of a single batch from dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# idx = ret[0]\n",
    "# src = ret[1]\n",
    "# cell_id = ret[2]\n",
    "# drug_id = ret[3]\n",
    "# auc = ret[4]\n",
    "# ccl_fea = ret[5]\n",
    "# drg_fea = ret[6]\n",
    "\n",
    "# display(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# x = torch.cat((ccl_fea, drg_fea), dim=1)\n",
    "\n",
    "# # Expanded\n",
    "# x = model.fc1(x)\n",
    "# x = model.bn1(x)\n",
    "# x = F.relu(x)\n",
    "\n",
    "# x = model.fc2(x)\n",
    "# x = model.bn2(x)\n",
    "# x = F.relu(x)\n",
    "# x = F.dropout(x, p=model.dr_rate, training=model.training)\n",
    "\n",
    "# x = model.fc3(x)\n",
    "# x = model.bn3(x)\n",
    "# x = F.relu(x)\n",
    "# x = F.dropout(x, p=model.dr_rate, training=model.training)\n",
    "\n",
    "# x = model.fc4(x)\n",
    "# x = model.bn4(x)\n",
    "# x = F.relu(x)\n",
    "# x = F.dropout(x, p=model.dr_rate, training=model.training)\n",
    "\n",
    "# x = model.fc5(x)\n",
    "# x = model.bn5(x)\n",
    "# x = F.relu(x)\n",
    "# x = F.dropout(x, p=model.dr_rate, training=model.training)\n",
    "\n",
    "# x = model.fc6(x)\n",
    "# x = model.bn6(x)\n",
    "# x = F.relu(x)\n",
    "# x = F.dropout(x, p=model.dr_rate, training=model.training)\n",
    "\n",
    "# x = model.fc7(x)\n",
    "# x = model.bn7(x)\n",
    "# x = F.relu(x)\n",
    "# x = F.dropout(x, p=model.dr_rate, training=model.training)\n",
    "\n",
    "# x = model.fc8(x)\n",
    "# x = F.relu(x)\n",
    "\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define optimer, learning rate decay\n",
    "Optimizers, learning rate decay, and miscellaneous in github.com/xduan7/UnoPytorch/blob/master/uno_pytorch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "# resp_opt = get_opt(opt_type=args.resp_opt, networks=resp_net, learning_rate=args.resp_lr, l2_regularization=args.l2_regularization)\n",
    "opt = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)  # pytorch.org/docs/stable/optim.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate scheduler\n",
    "# resp_lr_decay = LambdaLR(optimizer=resp_opt, lr_lambda=lambda e: args.lr_decay_factor ** e)\n",
    "\n",
    "# CLR (pytorch.org/docs/stable/optim.html)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer=opt, base_lr=1e-4, max_lr=1e-3, mode='triangular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resp_loss_func = F.l1_loss if args.resp_loss_func == 'l1' else F.mse_loss\n",
    "loss_fnc = nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Test --- try a single training iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ccl_fea.dtype: torch.float32\n",
      "drg_fea.dtype: torch.float32\n",
      "auc.dtype: torch.float64\n",
      "\n",
      "pred.shape torch.Size([32, 1])\n",
      "auc.shape torch.Size([32])\n",
      "auc.shape torch.Size([32, 1])\n",
      "\n",
      "pred:\n",
      " tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:3', grad_fn=<SliceBackward>)\n",
      "auc:\n",
      " tensor([[0.7201],\n",
      "        [0.9537],\n",
      "        [0.8879]], device='cuda:3', dtype=torch.float64)\n",
      "pred:\n",
      " tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:3', dtype=torch.float64, grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "idx, src, cell_id, drug_id, auc, ccl_fea, drg_fea = next(iter(tr_loader))  # (idx, SOURCE, ccl_id, drg_id, auc, ccl_fea, drg_fea)\n",
    "\n",
    "auc = auc.to(device)\n",
    "ccl_fea = ccl_fea.to(device)\n",
    "drg_fea = drg_fea.to(device)\n",
    "fea_dct = {'ccl_fea': ccl_fea, 'drg_fea': drg_fea}\n",
    "\n",
    "print('ccl_fea.dtype:', ccl_fea.dtype)\n",
    "print('drg_fea.dtype:', drg_fea.dtype)\n",
    "print('auc.dtype:', auc.dtype)\n",
    "print('')\n",
    "\n",
    "# Forward\n",
    "opt.zero_grad()\n",
    "# pred = model(ccl_fea=ccl_fea, drg_fea=drg_fea)\n",
    "pred = model(**fea_dct)\n",
    "\n",
    "print(f'pred.shape {pred.shape}')\n",
    "print(f'auc.shape {auc.shape}')\n",
    "auc = auc.view(pred.shape)\n",
    "print(f'auc.shape {auc.shape}\\n')\n",
    "\n",
    "print('pred:\\n', pred[:3])\n",
    "print('auc:\\n', auc[:3])\n",
    "pred = pred.type(auc.dtype)\n",
    "print('pred:\\n', pred[:3])\n",
    "\n",
    "# Backprop\n",
    "loss = loss_fnc(pred, auc)\n",
    "loss.backward() # compute loss gradients wrt to model parameters and inputs\n",
    "opt.step()      # update model parameters;  pytorch.org/docs/stable/optim.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Training loops\n",
    "Training/validation loops in github.com/xduan7/UnoPytorch/blob/master/uno_pytorch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# val_cl_clf_acc = []\n",
    "# val_drug_target_acc = []\n",
    "# val_drug_qed_mse, val_drug_qed_mae, val_drug_qed_r2 = [], [], []\n",
    "val_resp_mse, val_resp_mae, val_resp_r2 = [], [], []\n",
    "\n",
    "best_r2 = -np.inf\n",
    "patience = 0\n",
    "start_time = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create folder for validation results if not exist\n",
    "# os.makedirs(args.val_results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Early stopping is decided on the validation set with the same data source as the training dataloader\n",
    "# val_index = 0\n",
    "# for idx, loader in enumerate(drug_resp_val_loaders):\n",
    "#     if loader.dataset.data_source == args.trn_src:\n",
    "#         val_index = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "max_epochs = 2\n",
    "for epoch in range(max_epochs): # args.max_num_epochs\n",
    "\n",
    "    print('=' * 80 + '\\nTraining Epoch %3i:' % (epoch + 1))\n",
    "    epoch_start_time = time()\n",
    "    # resp_lr_decay.step(epoch)\n",
    "    lr_scheduler.step(epoch)\n",
    "    \n",
    "    train_resp(\n",
    "        device = device,\n",
    "        resp_net = resp_net,\n",
    "        data_loader = drug_resp_trn_loader,\n",
    "        max_num_batches = args.max_num_batches,\n",
    "        loss_func = resp_loss_func,\n",
    "        optimizer = resp_opt)\n",
    "\n",
    "    print('\\nValidation Results:')\n",
    "    \n",
    "    if epoch >= args.resp_val_start_epoch:\n",
    "        \n",
    "        resp_mse, resp_mae, resp_r2 = valid_resp(\n",
    "            epoch=epoch,\n",
    "            trn_src=args.trn_src,\n",
    "            device=device,\n",
    "            resp_net=resp_net,\n",
    "            data_loaders=drug_resp_val_loaders,\n",
    "            resp_uq=args.resp_uq,\n",
    "            resp_uq_dropout=args.resp_uq_dropout,\n",
    "            resp_uq_num_runs=args.resp_uq_num_runs,\n",
    "            val_results_dir=args.val_results_dir)\n",
    "\n",
    "        # Save the validation results in nested list\n",
    "        val_resp_mse.append(resp_mse)\n",
    "        val_resp_mae.append(resp_mae)\n",
    "        val_resp_r2.append(resp_r2)\n",
    "\n",
    "        # Record the best R2 score (same data source)\n",
    "        # and check for early stopping if no improvement for epochs\n",
    "        if resp_r2[val_index] > best_r2:\n",
    "            patience = 0\n",
    "            best_r2 = resp_r2[val_index]\n",
    "        else:\n",
    "            patience += 1\n",
    "        if patience >= args.early_stop_patience:\n",
    "            print('Validation results does not improve for %d epochs ... '\n",
    "                  'invoking early stopping.' % patience)\n",
    "            break\n",
    "\n",
    "    print('Epoch Running Time: %.1f Seconds.' % (time.time() - epoch_start_time))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_resp_r2 = np.array(val_resp_r2)\n",
    "val_resp_mse, val_resp_mae, val_resp_r2 = \\\n",
    "    np.array(val_resp_mse).reshape(-1, len(args.val_srcs)), \\\n",
    "    np.array(val_resp_mae).reshape(-1, len(args.val_srcs)), \\\n",
    "    np.array(val_resp_r2).reshape(-1, len(args.val_srcs))\n",
    "\n",
    "print('Program Running Time: %.1f Seconds.' % (time.time() - start_time))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loops (ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_torch(y_true, y_pred):\n",
    "    epsilon = 1e-7  # this epsilon value used in TF\n",
    "    SS_res = torch.sum( (y_true - y_pred)**2 )\n",
    "    SS_tot = torch.sum( (y_true - torch.mean(y_true))**2 )\n",
    "    r2 = 1 - SS_res / (SS_tot + epsilon)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_scores_reg(pred, true, scores):\n",
    "    \"\"\" Updates score metrics for regression ML predictions.\n",
    "    The scores are summed for every call of the function (single func call corresponds a single batch).\n",
    "    \n",
    "    Note: these must be implemented with pytroch commands! Otherwise, results gives error:\n",
    "    RuntimeError: Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead.   \n",
    "    pred, true = pred.numpy(), yy.numpy()\n",
    "    tr_mae += sklearn.metrics.mean_absolute_error(true, pred)\n",
    "    tr_r2 += sklearn.metrics.r2_score(true, pred)\n",
    "    \"\"\"\n",
    "    for m in scores.keys():\n",
    "        if 'loss' in m:\n",
    "            continue\n",
    "            \n",
    "        elif any([True if v in m else False for v in ['mean_abs_err', 'mean_absolute_error']]):\n",
    "            scores[m] += torch.mean( torch.abs(pred-true) ).item()\n",
    "\n",
    "        elif any([True if v in m else False for v in ['median_abs_err', 'median_absolute_error']]):\n",
    "            scores[m] += torch.median( torch.abs(pred-true) ).item()\n",
    "\n",
    "        elif any([True if v in m else False for v in ['mean_sqrd_err', 'mean_squared_error']]):\n",
    "            scores[m] += torch.mean( torch.pow(pred-true, 0.5) ).item()  # or torch.mean(torch.sqrt(pred-true))\n",
    "            \n",
    "        elif any([True if v in m else False for v in ['r2', 'r2_score']]):\n",
    "            scores[m] += r2_torch(y_true=true, y_pred=pred).item()\n",
    "            \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_batch(xx_dct, yy, model, loss_fnc, opt=None):\n",
    "    \"\"\" \n",
    "    Args:\n",
    "        opt (torch.optim) : no backprop is performed if optimizer is not provided (for val or test) \n",
    "    \"\"\"\n",
    "    pred = model(**xx_dct)\n",
    "    pred = pred.type(yy.dtype)\n",
    "    loss = loss_fnc(pred, yy)\n",
    "    \n",
    "    # Backward pass\n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "    return loss, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model: nn.Module,\n",
    "        loss_fnc,\n",
    "        opt: torch.optim,\n",
    "        tr_dl: torch.utils.data.DataLoader,\n",
    "        vl_dl: torch.utils.data.DataLoader=None,\n",
    "        epochs: int=1,\n",
    "        device: torch.device='cuda:0',\n",
    "        verbose: bool=True,\n",
    "        metrics=[]) -> dict:\n",
    "    \"\"\" github.com/stared/livelossplot/blob/master/examples/pytorch.ipynb\n",
    "    Args:\n",
    "        metrics (list) : list of metric scores to log\n",
    "            (available metrics: 'mean_abs_err','median_abs_err', 'mean_sqrd_err', 'r2)\n",
    "    \"\"\" \n",
    "    print(f'Arg `device`: {device}')\n",
    "    model.to(device)\n",
    "    print('current_device:', torch.cuda.current_device())\n",
    "    \n",
    "    # Choose cuda device with context manager --> try using context manager!!!\n",
    "    # with torch.cuda.device(device):\n",
    "        \n",
    "    # Create dicts to log scores\n",
    "    if vl_dl is None:\n",
    "        logs = OrderedDict({'loss': []})\n",
    "        logs.update(OrderedDict({m: [] for m in metrics}))        \n",
    "    else:\n",
    "        logs = OrderedDict({'loss': [], 'val_loss': []})\n",
    "        for m in metrics: logs.update(OrderedDict({m: [], 'val_'+m: []}))\n",
    "    \n",
    "    # Iter over epochs\n",
    "    phases = ['train', 'val'] if vl_dl is not None else ['train']\n",
    "    for ep in range(epochs):\n",
    "        ep_t0 = time()\n",
    "        # lr_scheduler.step()\n",
    "        \n",
    "        for ph in phases:\n",
    "            if ph == 'train':\n",
    "                model.train()\n",
    "                dl = tr_dl\n",
    "                scores = {m: 0 for m in logs.keys() if 'val' not in m}\n",
    "                loss_name = 'loss'\n",
    "            elif ph == 'val':\n",
    "                model.eval()\n",
    "                dl = vl_dl\n",
    "                scores = {m: 0 for m in logs.keys() if 'val' in m}\n",
    "                loss_name = 'val_loss'\n",
    "\n",
    "            # Iter over batches\n",
    "            for _, _, _, _, auc, ccl_fea, drg_fea in dl:\n",
    "                # discuss.pytorch.org/t/expected-object-of-scalar-type-long-but-got-scalar-type-float-for-argument-2-target/33102\n",
    "                auc = auc.to(device, dtype=torch.float32) # dtype=torch.float32 fixed an error\n",
    "                ccl_fea = ccl_fea.to(device)\n",
    "                drg_fea = drg_fea.to(device)\n",
    "                fea_dct = {'ccl_fea': ccl_fea, 'drg_fea': drg_fea}\n",
    "                \n",
    "                # Process batch\n",
    "#                 if ph == 'train':\n",
    "#                     loss, pred = proc_batch(xx_dct=fea_dct, yy=auc, model=model, loss_fnc=loss_fnc, opt=opt)\n",
    "#                 else:\n",
    "#                     loss, pred = proc_batch(xx_dct=fea_dct, yy=auc, model=model, loss_fnc=loss_fnc, opt=None)                \n",
    "\n",
    "                pred = model(ccl_fea=ccl_fea, drg_fea=drg_fea).type(auc.dtype)\n",
    "                loss = loss_fnc(pred, auc)\n",
    "                if opt is not None:\n",
    "                    opt.zero_grad()\n",
    "                    loss.backward()\n",
    "                    opt.step()\n",
    "                \n",
    "                # Compute metrics (running avg)\n",
    "                scores[loss_name] += loss.item()\n",
    "                scores = update_scores_reg(pred=pred, true=auc, scores=scores)\n",
    "            \n",
    "            # Log scores\n",
    "            for m in scores.keys():\n",
    "                logs[m].append(scores[m]/len(dl))\n",
    "            \n",
    "        # del xx, yy, loss, pred, scores\n",
    "        del ccl_fea, drg_fea, auc, loss, pred, scores\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'Epoch {ep+1}/{epochs}; ',\n",
    "                  f'{int(time()-ep_t0)}s; ',\n",
    "                  [f'{k}: {v[-1]:.3f}' for k, v in logs.items()])\n",
    "            \n",
    "        # TODO: log scores into file\n",
    "\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arg `device`: cuda:3\n",
      "current_device: 0\n",
      "Epoch 1/30;  15s;  ['loss: 0.113', 'val_loss: 0.036', 'mean_abs_err: 0.253', 'val_mean_abs_err: 0.155', 'r2: -242.482', 'val_r2: -193.656']\n",
      "Epoch 2/30;  14s;  ['loss: 0.042', 'val_loss: 0.030', 'mean_abs_err: 0.162', 'val_mean_abs_err: 0.140', 'r2: -983.738', 'val_r2: -159.400']\n",
      "Epoch 3/30;  15s;  ['loss: 0.034', 'val_loss: 0.028', 'mean_abs_err: 0.145', 'val_mean_abs_err: 0.133', 'r2: -48.536', 'val_r2: -146.633']\n",
      "Epoch 4/30;  14s;  ['loss: 0.031', 'val_loss: 0.028', 'mean_abs_err: 0.137', 'val_mean_abs_err: 0.131', 'r2: -61.513', 'val_r2: -143.833']\n",
      "Epoch 5/30;  14s;  ['loss: 0.029', 'val_loss: 0.027', 'mean_abs_err: 0.133', 'val_mean_abs_err: 0.130', 'r2: -156.263', 'val_r2: -141.217']\n",
      "Epoch 6/30;  15s;  ['loss: 0.028', 'val_loss: 0.027', 'mean_abs_err: 0.131', 'val_mean_abs_err: 0.128', 'r2: -83.337', 'val_r2: -139.741']\n",
      "Epoch 7/30;  14s;  ['loss: 0.028', 'val_loss: 0.027', 'mean_abs_err: 0.130', 'val_mean_abs_err: 0.128', 'r2: -39.561', 'val_r2: -139.138']\n",
      "Epoch 8/30;  14s;  ['loss: 0.027', 'val_loss: 0.027', 'mean_abs_err: 0.129', 'val_mean_abs_err: 0.127', 'r2: -74.457', 'val_r2: -138.373']\n",
      "Epoch 9/30;  14s;  ['loss: 0.027', 'val_loss: 0.027', 'mean_abs_err: 0.128', 'val_mean_abs_err: 0.128', 'r2: -43.991', 'val_r2: -138.763']\n",
      "Epoch 10/30;  14s;  ['loss: 0.027', 'val_loss: 0.027', 'mean_abs_err: 0.128', 'val_mean_abs_err: 0.129', 'r2: -328.902', 'val_r2: -140.023']\n",
      "Epoch 11/30;  15s;  ['loss: 0.027', 'val_loss: 0.027', 'mean_abs_err: 0.128', 'val_mean_abs_err: 0.127', 'r2: -58.276', 'val_r2: -138.446']\n",
      "Epoch 12/30;  14s;  ['loss: 0.027', 'val_loss: 0.027', 'mean_abs_err: 0.128', 'val_mean_abs_err: 0.128', 'r2: -241.922', 'val_r2: -138.996']\n",
      "Epoch 13/30;  14s;  ['loss: 0.027', 'val_loss: 0.027', 'mean_abs_err: 0.128', 'val_mean_abs_err: 0.127', 'r2: -34.870', 'val_r2: -138.532']\n",
      "Epoch 14/30;  14s;  ['loss: 0.027', 'val_loss: 0.027', 'mean_abs_err: 0.128', 'val_mean_abs_err: 0.127', 'r2: -32.980', 'val_r2: -138.148']\n",
      "Epoch 15/30;  15s;  ['loss: 0.027', 'val_loss: 0.027', 'mean_abs_err: 0.127', 'val_mean_abs_err: 0.127', 'r2: -88.158', 'val_r2: -138.001']\n",
      "Epoch 16/30;  15s;  ['loss: 0.027', 'val_loss: 0.027', 'mean_abs_err: 0.127', 'val_mean_abs_err: 0.128', 'r2: -105.535', 'val_r2: -139.098']\n",
      "Epoch 17/30;  14s;  ['loss: 0.027', 'val_loss: 0.027', 'mean_abs_err: 0.127', 'val_mean_abs_err: 0.127', 'r2: -63.508', 'val_r2: -137.851']\n",
      "Epoch 18/30;  14s;  ['loss: 0.027', 'val_loss: 0.027', 'mean_abs_err: 0.127', 'val_mean_abs_err: 0.127', 'r2: -60.969', 'val_r2: -137.925']\n",
      "Epoch 19/30;  15s;  ['loss: 0.027', 'val_loss: 0.027', 'mean_abs_err: 0.127', 'val_mean_abs_err: 0.126', 'r2: -87.397', 'val_r2: -137.815']\n",
      "Epoch 20/30;  15s;  ['loss: 0.027', 'val_loss: 0.027', 'mean_abs_err: 0.127', 'val_mean_abs_err: 0.127', 'r2: -63.073', 'val_r2: -138.513']\n",
      "Epoch 21/30;  15s;  ['loss: 0.027', 'val_loss: 0.027', 'mean_abs_err: 0.127', 'val_mean_abs_err: 0.127', 'r2: -66.744', 'val_r2: -138.376']\n",
      "Epoch 22/30;  14s;  ['loss: 0.027', 'val_loss: 0.027', 'mean_abs_err: 0.127', 'val_mean_abs_err: 0.126', 'r2: -89.472', 'val_r2: -137.603']\n",
      "Epoch 23/30;  15s;  ['loss: 0.027', 'val_loss: 0.027', 'mean_abs_err: 0.127', 'val_mean_abs_err: 0.127', 'r2: -86.646', 'val_r2: -138.053']\n",
      "Epoch 24/30;  15s;  ['loss: 0.027', 'val_loss: 0.027', 'mean_abs_err: 0.127', 'val_mean_abs_err: 0.127', 'r2: -101.317', 'val_r2: -137.876']\n",
      "Epoch 25/30;  15s;  ['loss: 0.027', 'val_loss: 0.027', 'mean_abs_err: 0.127', 'val_mean_abs_err: 0.127', 'r2: -106.202', 'val_r2: -137.769']\n",
      "Epoch 26/30;  14s;  ['loss: 0.027', 'val_loss: 0.027', 'mean_abs_err: 0.127', 'val_mean_abs_err: 0.127', 'r2: -96.556', 'val_r2: -138.070']\n",
      "Epoch 27/30;  15s;  ['loss: 0.027', 'val_loss: 0.027', 'mean_abs_err: 0.127', 'val_mean_abs_err: 0.127', 'r2: -36.074', 'val_r2: -138.261']\n",
      "Epoch 28/30;  15s;  ['loss: 0.027', 'val_loss: 0.027', 'mean_abs_err: 0.127', 'val_mean_abs_err: 0.126', 'r2: -37.453', 'val_r2: -137.785']\n",
      "Epoch 29/30;  14s;  ['loss: 0.027', 'val_loss: 0.027', 'mean_abs_err: 0.127', 'val_mean_abs_err: 0.127', 'r2: -127.475', 'val_r2: -137.795']\n",
      "Epoch 30/30;  14s;  ['loss: 0.027', 'val_loss: 0.027', 'mean_abs_err: 0.127', 'val_mean_abs_err: 0.127', 'r2: -58.624', 'val_r2: -137.851']\n"
     ]
    }
   ],
   "source": [
    "metrics = ['mean_abs_err', 'r2']\n",
    "device = 'cuda:3'\n",
    "verbose = True\n",
    "epochs = 30\n",
    "fit_kwargs = {'epochs': epochs, 'device': device, 'verbose': verbose, 'metrics': metrics}\n",
    "\n",
    "logs = fit(model=model,\n",
    "           loss_fnc=loss_fnc,\n",
    "           opt=opt,\n",
    "           tr_dl=tr_loader,\n",
    "           vl_dl=vl_loader,\n",
    "           **fit_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "# plt.plot(logs['loss'], label='loss');\n",
    "# plt.plot(logs['val_loss'], label='val_loss');\n",
    "# plt.legend(loc='best');\n",
    "\n",
    "# plt.plot(logs['mean_abs_err'], label='mean_abs_err');\n",
    "# plt.plot(logs['val_mean_abs_err'], label='val_mean_abs_err');\n",
    "# plt.legend(loc='best');\n",
    "\n",
    "plt.plot(logs['r2'], label='r2');\n",
    "plt.plot(logs['val_r2'], label='val_r2');\n",
    "plt.legend(loc='best');\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:p1_] *",
   "language": "python",
   "name": "conda-env-p1_-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
