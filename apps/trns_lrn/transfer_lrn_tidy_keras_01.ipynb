{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from glob import glob\n",
    "\n",
    "import sklearn\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch import nn, optim\n",
    "# from torch.optim import lr_scheduler\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# import copy\n",
    "# print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Dropout, Activation, BatchNormalization, Lambda, merge\n",
    "from keras import optimizers\n",
    "from keras.optimizers import SGD, Adam, RMSprop, Adadelta\n",
    "from keras.models import Sequential, Model, model_from_json, model_from_yaml, load_model\n",
    "from keras.utils import np_utils, multi_gpu_model\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard    \n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# medium.com/@prateekvishnu/xavier-and-he-normal-he-et-al-initialization-8e3d7a087528\n",
    "def krs_reg_tidy(input_dim, dr_rate=0.2, opt_name='sgd', kernel_initializer='he_uniform', logger=None):\n",
    "    inputs = Input(shape=(input_dim,), name='inputs')\n",
    "\n",
    "    layers = [1000, 500, 250, 125, 60]\n",
    "    for i, l_size in enumerate(layers):\n",
    "        if i == 0:\n",
    "            x = Dense(l_size, kernel_initializer=kernel_initializer, name=f'fc{i+1}')(inputs)\n",
    "        else:\n",
    "            x = Dense(l_size, kernel_initializer=kernel_initializer, name=f'fc{i+1}')(x)\n",
    "        x = BatchNormalization(name=f'bn{i+1}')(x)\n",
    "        x = Activation('relu', name=f'a{i+1}')(x)\n",
    "        x = Dropout(dr_rate, name=f'drp{i+1}')(x)\n",
    "        \n",
    "#     x = Dense(1000, name='fc1')(inputs)\n",
    "#     x = BatchNormalization(name='bn1')(x)\n",
    "#     x = Activation('relu')(x)\n",
    "\n",
    "#     x = Dense(1000, name='fc2')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Activation('relu')(x)\n",
    "#     x = Dropout(dr_rate)(x)\n",
    "\n",
    "#     x = Dense(500, name='fc3')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Activation('relu')(x)\n",
    "#     x = Dropout(dr_rate)(x)\n",
    "\n",
    "#     x = Dense(250, name='fc4')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Activation('relu')(x)\n",
    "#     x = Dropout(dr_rate)(x)\n",
    "\n",
    "#     x = Dense(125, name='fc5')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Activation('relu')(x)\n",
    "#     x = Dropout(dr_rate)(x)\n",
    "\n",
    "#     x = Dense(60, name='fc6')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Activation('relu')(x)\n",
    "#     x = Dropout(dr_rate)(x)\n",
    "\n",
    "#     x = Dense(30, name='fc7')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Activation('relu')(x)\n",
    "#     x = Dropout(dr_rate)(x)\n",
    "\n",
    "    outputs = Dense(1, activation='relu', name='outputs')(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    if opt_name == 'sgd':\n",
    "        opt = SGD(lr=1e-4, momentum=0.9)\n",
    "    elif opt_name == 'adam':\n",
    "        opt = Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    else:\n",
    "        opt = SGD(lr=1e-4, momentum=0.9) # for clr\n",
    "\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data path\n",
    "\n",
    "# Top6 from Rick\n",
    "# datadir = Path('../data/processed/topN/topNrick/')\n",
    "# datapath = datadir/'uniq.top6.reg.parquet'\n",
    "\n",
    "# Top6 from code\n",
    "# datadir = Path('../data/processed/topN/topNcode/')\n",
    "# datapath = datadir/'top_6.res_reg.cf_rnaseq.dd_dragon7.labled.parquet'\n",
    "\n",
    "dirpath = Path('../../data/processed/data_splits/gdsc_cv_simple_te_simple_combat/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Args\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\";\n",
    "\n",
    "target_name = 'AUC'\n",
    "cv_folds = 1\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "n_jobs = 4\n",
    "verbose=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_id 119011\n",
      "vl_id 3000\n",
      "te_id 13556\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "if (dirpath/'xdata.parquet').is_file():\n",
    "    xdata = pd.read_parquet( dirpath/'xdata.parquet', engine='auto', columns=None )\n",
    "    meta = pd.read_parquet( dirpath/'meta.parquet', engine='auto', columns=None )\n",
    "    ydata = meta[[target_name]]\n",
    "\n",
    "tr_id = pd.read_csv( dirpath/f'{cv_folds}fold_tr_id.csv' ).values.reshape(-1,)\n",
    "vl_id = pd.read_csv( dirpath/f'{cv_folds}fold_vl_id.csv' ).values.reshape(-1,)\n",
    "te_id = pd.read_csv( dirpath/'te_id.csv' ).values.reshape(-1,)\n",
    "\n",
    "src = dirpath.name.split('_')[0]\n",
    "\n",
    "print('tr_id', len(tr_id))\n",
    "print('vl_id', len(vl_id))\n",
    "print('te_id', len(te_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take subset of training samples for faster development\n",
    "n = 40000\n",
    "tr_id = np.random.permutation(len(tr_id))[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 3762) (40000, 1)\n",
      "(3000, 3762) (3000, 1)\n",
      "(13556, 3762) (13556, 1)\n"
     ]
    }
   ],
   "source": [
    "# Train / val / test\n",
    "xtr = xdata.iloc[tr_id]\n",
    "xvl = xdata.iloc[vl_id]\n",
    "xte = xdata.iloc[te_id]\n",
    "\n",
    "ytr = ydata.iloc[tr_id]\n",
    "yvl = ydata.iloc[vl_id]\n",
    "yte = ydata.iloc[te_id]\n",
    "\n",
    "print(xtr.shape, ytr.shape)\n",
    "print(xvl.shape, yvl.shape)\n",
    "print(xte.shape, yte.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler = RobustScaler()\n",
    "\n",
    "cols = xtr.columns\n",
    "xtr = pd.DataFrame(scaler.fit_transform(xtr), columns=cols, dtype=np.float32)\n",
    "xvl = pd.DataFrame(scaler.transform(xvl), columns=cols, dtype=np.float32)\n",
    "xte = pd.DataFrame(scaler.transform(xte), columns=cols, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train base NN  model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/keras-team/keras/issues/8772<br>\n",
    "https://forums.fast.ai/t/how-to-finetune-with-new-keras-api/2328/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = krs_reg_tidy(input_dim=xtr.shape[1], dr_rate=0.2, opt_name='sgd')\n",
    "# fit_kwargs = {'epochs': epochs, 'batch_size': batch_size, 'verbose': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = base_model.fit(xtr, ytr, **fit_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save model\n",
    "# base_model.save('base_nn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict\n",
    "# pred_ytr = base_model.predict(xtr)\n",
    "\n",
    "# # Calc scores\n",
    "# tr_scores = {}\n",
    "# tr_scores['r2'] = r2_score(ytr, pred_ytr)\n",
    "# tr_scores['mae'] = mean_absolute_error(ytr, pred_ytr)\n",
    "# print(tr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_layers(model, print_all=False):\n",
    "    \"\"\" Print the trainable state of layers. \"\"\"\n",
    "    print('Trainable layers:')\n",
    "    for layer in model.layers:\n",
    "        if layer.trainable:\n",
    "            print(layer.name, layer.trainable)\n",
    "        if not layer.trainable and print_all:\n",
    "            print(layer.name, layer.trainable)\n",
    "\n",
    "def freeze_layers(model, layers_ids='all'):\n",
    "    # freeze_layers = ['1', '2', '3', '4']\n",
    "    if layers_ids=='all':\n",
    "        for layer in ft_model.layers:\n",
    "            layer.trainable = False\n",
    "            \n",
    "    for layer in ft_model.layers:\n",
    "        if any([True for i in layers_ids if i in layer.name]):\n",
    "            layer.trainable = False\n",
    "            \n",
    "def pop_layers(model, layers_ids):\n",
    "    # pop_layers = ['4', '5', 'outputs']\n",
    "    model_layers = fe_model.layers\n",
    "    for layer in model_layers[::-1]:\n",
    "        if any([True for i in layers_ids if i in layer.name]):\n",
    "            fe_model.layers.pop()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../../out/trns_lrn/train_base_model_keras/GDSC.nn_reg0.sgd.ep200.drp0.2_2019-7-21_h19-m25')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_dir = Path('../../out/trns_lrn/train_base_model_keras/GDSC.nn_reg0.sgd.ep200.drp0.2_2019-7-21_h19-m25')\n",
    "\n",
    "# base_model_name = 'GDSC.nn_reg0.sgd.ep200.drp0.2_2019-7-21_h19-m25'\n",
    "# base_model_path = base_model_dir / base_model_name\n",
    "# base_model_path\n",
    "                      \n",
    "base_model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CCLE'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl_data_dir = Path('/vol/ml/apartin/projects/pilot1/data/yitan/Data/tidy/CCLE.geneGE.DD')\n",
    "# tl_data_name = 'CCLE.geneGE.DD'\n",
    "# tl_data_path = tl_data_dir / tl_data_name\n",
    "# src = tl_data_name.split('.')[0]\n",
    "# tl_data_path\n",
    "\n",
    "src = str(tl_data_dir).split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for getting tidy data (Yitan's partitions)\n",
    "\n",
    "def extract_subset_fea(df, fea_list, fea_sep='_'):\n",
    "    \"\"\" Extract features based feature prefix name. \"\"\"\n",
    "    fea = [c for c in df.columns if (c.split(fea_sep)[0]) in fea_list]\n",
    "    df = df[fea]\n",
    "    return df\n",
    "\n",
    "def extract_data(df, fea_list):\n",
    "    \"\"\" ... \"\"\"\n",
    "    X = extract_subset_fea(df, fea_list=fea_list, fea_sep='_')\n",
    "    Y = df[['auc']]\n",
    "    meta = df.drop(columns=X.columns)\n",
    "    meta = meta.drop(columns=['auc'])\n",
    "    return X, Y, meta\n",
    "\n",
    "def load_data(dirpath, src, fold=0, ccl_fea_list=['geneGE'], drg_fea_list=['DD']):\n",
    "    data_fpath = Path((glob(str(dirpath/'*data.parquet')))[0])\n",
    "    assert data_fpath.is_file(), '*data.parquet file was not found.'\n",
    "    data = pd.read_parquet( data_fpath )\n",
    "    print('\\ndata {}'.format(data.shape))\n",
    "\n",
    "    # Path to data splits\n",
    "    datadir = Path('../../data/yitan/Data')\n",
    "    ccl_folds_dir = Path('../../data/yitan/CCL_10Fold_Partition')\n",
    "    pdm_folds_dir = Path('../../data/yitan/PDM_10Fold_Partition')\n",
    "\n",
    "    # fold = 0\n",
    "    # ccl_fea_list = ['geneGE']\n",
    "    # drg_fea_list = ['DD']\n",
    "    fea_sep = '_'\n",
    "\n",
    "    ids_path = ccl_folds_dir/f'{src}/cv_{fold}' # 'TestList.txt'\n",
    "    tr_ids_list = pd.read_csv(ids_path/'TrainList.txt', header=None).squeeze().values\n",
    "    vl_ids_list = pd.read_csv(ids_path/'ValList.txt', header=None).squeeze().values\n",
    "    te_ids_list = pd.read_csv(ids_path/'TestList.txt', header=None).squeeze().values\n",
    "\n",
    "    data_tr = data[ data['cclname'].isin( tr_ids_list ) ]\n",
    "    data_vl = data[ data['cclname'].isin( vl_ids_list ) ]\n",
    "    data_te = data[ data['cclname'].isin( te_ids_list ) ]\n",
    "\n",
    "    print('data_tr {}'.format(data_tr.shape))\n",
    "    print('data_vl {}'.format(data_vl.shape))\n",
    "    print('data_te {}'.format(data_te.shape))\n",
    "\n",
    "    xtr, ytr, mtr = extract_data(data_tr, fea_list = ccl_fea_list + drg_fea_list)\n",
    "    xvl, yvl, mvl = extract_data(data_vl, fea_list = ccl_fea_list + drg_fea_list)\n",
    "    xte, yte, mte = extract_data(data_te, fea_list = ccl_fea_list + drg_fea_list)\n",
    "\n",
    "    # Scale\n",
    "    cols = xtr.columns\n",
    "    # scaler = StandardScaler()\n",
    "    scaler = MinMaxScaler()\n",
    "    # scaler = RobustScaler()\n",
    "\n",
    "    cols = xtr.columns\n",
    "    xtr = pd.DataFrame(scaler.fit_transform(xtr), columns=cols, dtype=np.float32)\n",
    "    xvl = pd.DataFrame(scaler.transform(xvl), columns=cols, dtype=np.float32)\n",
    "    xte = pd.DataFrame(scaler.transform(xte), columns=cols, dtype=np.float32)\n",
    "    \n",
    "    return xtr, xvl, xte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "data (10971, 4254)\n",
      "data_tr (8755, 4254)\n",
      "data_vl (1117, 4254)\n",
      "data_te (1099, 4254)\n"
     ]
    }
   ],
   "source": [
    "xtr, xvl, xte = load_data(dirpath=tl_data_dir, src=src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline methods\n",
    "\n",
    "1. Train model from scratch on tf set\n",
    "2. Predict on the tf set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0721 09:44:07.621711 140460894680896 deprecation_wrapper.py:119] From /vol/ml/apartin/anaconda3/envs/p1_/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0721 09:44:07.635463 140460894680896 deprecation_wrapper.py:119] From /vol/ml/apartin/anaconda3/envs/p1_/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0721 09:44:07.699430 140460894680896 deprecation_wrapper.py:119] From /vol/ml/apartin/anaconda3/envs/p1_/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0721 09:44:07.700080 140460894680896 deprecation_wrapper.py:119] From /vol/ml/apartin/anaconda3/envs/p1_/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0721 09:44:07.791278 140460894680896 deprecation.py:506] From /vol/ml/apartin/anaconda3/envs/p1_/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0721 09:44:08.133995 140460894680896 deprecation_wrapper.py:119] From /vol/ml/apartin/anaconda3/envs/p1_/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0721 09:44:08.855509 140460894680896 deprecation_wrapper.py:119] From /vol/ml/apartin/anaconda3/envs/p1_/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r2': 0.15539364998812022, 'mae': 0.11746149}\n"
     ]
    }
   ],
   "source": [
    "# NN\n",
    "b1_model = krs_reg_tidy(input_dim=xvl.shape[1], dr_rate=0.2, opt_name='sgd')\n",
    "fit_kwargs = {'epochs': epochs, 'batch_size': batch_size, 'verbose': False}\n",
    "history = b1_model.fit(xvl, yvl, **fit_kwargs)\n",
    "\n",
    "# Predict\n",
    "pred_yvl = b1_model.predict(xvl)\n",
    "\n",
    "# Calc scores\n",
    "b1_scores = {}\n",
    "b1_scores['r2'] = r2_score(yvl, pred_yvl)\n",
    "b1_scores['mae'] = mean_absolute_error(yvl, pred_yvl)\n",
    "print(b1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 0.23 mins\n",
      "{'r2': 0.9445182351870955, 'mae': 0.02806745983643786}\n"
     ]
    }
   ],
   "source": [
    "# LGBM\n",
    "init_kwargs = {'objective': 'regression', 'n_estimators': 100, 'n_jobs': n_jobs, 'random_state': SEED}    \n",
    "lgbm = lgb.LGBMModel(**init_kwargs)\n",
    "\n",
    "# Train\n",
    "fit_kwargs = {'verbose': verbose}\n",
    "t0 = time()\n",
    "lgbm.fit(xvl, yvl, **fit_kwargs)\n",
    "print('Train time: {:.2f} mins'.format( (time()-t0)/60 ))\n",
    "\n",
    "# Predict\n",
    "pred_yvl = lgbm.predict(xvl)\n",
    "\n",
    "# Calc scores\n",
    "lgbm_scores = {}\n",
    "lgbm_scores['r2'] = r2_score(yvl, pred_yvl)\n",
    "lgbm_scores['mae'] = mean_absolute_error(yvl, pred_yvl)\n",
    "print(lgbm_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Predict on target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r2': 0.38410798985450023, 'mae': 0.092168786}\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "base_model = load_model('base_nn_model.h5')\n",
    "pred_yvl = base_model.predict(xvl)\n",
    "\n",
    "# Scores\n",
    "b2_scores = {}\n",
    "b2_scores['r2'] = r2_score(yvl, pred_yvl)\n",
    "b2_scores['mae'] = mean_absolute_error(yvl, pred_yvl)\n",
    "print(b2_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning methods\n",
    "1. Freeze all layers, and reinitialize the last n layers (n=1, 2, ...)\n",
    "2. Freeze all layers, and finetune the last n layers (n=1, 2, ...)\n",
    "3. Freeze all layers, fea extract for tf, and then supply the extracted fea to LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Freeze all layers, and reinitialize the last n layers (n=1, 2, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Freeze all layers, and finetune the last n layers (n=1, 2, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = load_model('base_nn_model.h5')\n",
    "\n",
    "opt = SGD(lr=1e-4, momentum=0.9)\n",
    "# opt = Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "ft_model.compile(loss='mean_squared_error',\n",
    "                 optimizer=opt,\n",
    "                 metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable layers:\n",
      "fc1 True\n",
      "bn1 True\n",
      "a1 True\n",
      "dropout1 True\n",
      "fc2 True\n",
      "bn2 True\n",
      "a2 True\n",
      "dropout2 True\n",
      "fc3 True\n",
      "bn3 True\n",
      "a3 True\n",
      "dropout3 True\n",
      "fc4 True\n",
      "bn4 True\n",
      "a4 True\n",
      "dropout4 True\n",
      "fc5 True\n",
      "bn5 True\n",
      "a5 True\n",
      "dropout5 True\n",
      "outputs True\n"
     ]
    }
   ],
   "source": [
    "print_trainable_layers(ft_model, print_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fintune(model, freeze_layers, x, y, epoch=10, batch_size=32, verbose=False):\n",
    "#     freeze_layers = ['1', '2', '3', '4', '5']\n",
    "#     for layer in model.layers:\n",
    "#         if any([True for i in freeze_layers if i in layer.name]):\n",
    "#             layer.trainable = False\n",
    "            \n",
    "#     fit_kwargs = {'epochs': epochs, 'batch_size': batch_size, 'verbose': verbose}\n",
    "#     history = model.fit(x, y, **fit_kwargs)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable layers:\n",
      "inputs False\n",
      "fc1 False\n",
      "bn1 False\n",
      "a1 False\n",
      "dropout1 False\n",
      "fc2 False\n",
      "bn2 False\n",
      "a2 False\n",
      "dropout2 False\n",
      "fc3 False\n",
      "bn3 False\n",
      "a3 False\n",
      "dropout3 False\n",
      "fc4 False\n",
      "bn4 False\n",
      "a4 False\n",
      "dropout4 False\n",
      "fc5 True\n",
      "bn5 True\n",
      "a5 True\n",
      "dropout5 True\n",
      "outputs True\n"
     ]
    }
   ],
   "source": [
    "freeze_layers(ft_model, layers_ids=['1', '2', '3', '4'])\n",
    "print_trainable_layers(ft_model, print_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_epochs = 20\n",
    "fit_kwargs = {'epochs': ft_epochs, 'batch_size': batch_size, 'verbose': 0}\n",
    "history = ft_model.fit(xvl, yvl, **fit_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r2': 0.3907791476276462, 'mae': 0.092816226}\n"
     ]
    }
   ],
   "source": [
    "pred_yvl = ft_model.predict(xvl)\n",
    "\n",
    "# Calc scores\n",
    "ft2_scores = {}\n",
    "ft2_scores['r2'] = r2_score(yvl, pred_yvl)\n",
    "ft2_scores['mae'] = mean_absolute_error(yvl, pred_yvl)\n",
    "print(ft2_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Freeze all layers, fea extract, and then supply the extracted fea to LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable layers:\n",
      "inputs False\n",
      "fc1 True\n",
      "bn1 True\n",
      "a1 True\n",
      "dropout1 True\n",
      "fc2 True\n",
      "bn2 True\n",
      "a2 True\n",
      "dropout2 True\n",
      "fc3 True\n",
      "bn3 True\n",
      "a3 True\n",
      "dropout3 True\n",
      "fc4 True\n",
      "bn4 True\n",
      "a4 True\n",
      "dropout4 True\n",
      "fc5 True\n",
      "bn5 True\n",
      "a5 True\n",
      "dropout5 True\n",
      "outputs True\n"
     ]
    }
   ],
   "source": [
    "fe_model = load_model('base_nn_model.h5')\n",
    "print_trainable_layers(fe_model, print_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable layers:\n",
      "inputs False\n",
      "fc1 True\n",
      "bn1 True\n",
      "a1 True\n",
      "dropout1 True\n",
      "fc2 True\n",
      "bn2 True\n",
      "a2 True\n",
      "dropout2 True\n",
      "fc3 True\n",
      "bn3 True\n",
      "a3 True\n",
      "dropout3 True\n"
     ]
    }
   ],
   "source": [
    "pop_layers(fe_model, layers_ids=['4','5','outputs'])\n",
    "print_trainable_layers(fe_model, print_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 3762)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1000)              3763000   \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "a1 (Activation)              (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "a2 (Activation)              (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 250)               1000      \n",
      "_________________________________________________________________\n",
      "a3 (Activation)              (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dropout3 (Dropout)           (None, 250)               0         \n",
      "=================================================================\n",
      "Total params: 4,435,116\n",
      "Trainable params: 4,431,616\n",
      "Non-trainable params: 3,500\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fe_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs\n",
      "Tensor(\"inputs_14:0\", shape=(?, 3762), dtype=float32)\n",
      "Tensor(\"inputs_14:0\", shape=(?, 3762), dtype=float32)\n",
      "\n",
      "fc1\n",
      "Tensor(\"inputs_14:0\", shape=(?, 3762), dtype=float32)\n",
      "Tensor(\"fc1_14/BiasAdd:0\", shape=(?, 1000), dtype=float32)\n",
      "\n",
      "dropout3\n",
      "Tensor(\"a3_14/Relu:0\", shape=(?, 250), dtype=float32)\n",
      "Tensor(\"dropout3_14/cond/Merge:0\", shape=(?, 250), dtype=float32)\n",
      "\n",
      "[<tf.Tensor 'inputs_14:0' shape=(?, 3762) dtype=float32>]\n",
      "[<tf.Tensor 'outputs_14/Relu:0' shape=(?, 1) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "print(fe_model.layers[0].name)\n",
    "print(fe_model.layers[0].input)\n",
    "print(fe_model.layers[0].output)\n",
    "print('')\n",
    "\n",
    "print(fe_model.layers[1].name)\n",
    "print(fe_model.layers[1].input)\n",
    "print(fe_model.layers[1].output)\n",
    "print('')\n",
    "\n",
    "print(fe_model.layers[-1].name)\n",
    "print(fe_model.layers[-1].input)\n",
    "print(fe_model.layers[-1].output)\n",
    "print('')\n",
    "\n",
    "print(fe_model.inputs)\n",
    "print(fe_model.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature extractor model\n",
    "fea_extractor_model = Model(inputs=fe_model.input, outputs=fe_model.layers[-1].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 3762)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1000)              3763000   \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "a1 (Activation)              (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "a2 (Activation)              (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 250)               1000      \n",
      "_________________________________________________________________\n",
      "a3 (Activation)              (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dropout3 (Dropout)           (None, 250)               0         \n",
      "=================================================================\n",
      "Total params: 4,395,750\n",
      "Trainable params: 4,392,250\n",
      "Non-trainable params: 3,500\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fea_extractor_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'inputs_14:0' shape=(?, 3762) dtype=float32>]\n",
      "[<tf.Tensor 'dropout3_14/cond/Merge:0' shape=(?, 250) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "print(fea_extractor_model.inputs)\n",
    "print(fea_extractor_model.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 250)\n"
     ]
    }
   ],
   "source": [
    "xvl_fea = fea_extractor_model.predict(xvl)\n",
    "print(xvl_fea.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 0.02 mins\n",
      "{'r2': 0.9349332144023743, 'mae': 0.031395217119620546}\n"
     ]
    }
   ],
   "source": [
    "# Now train shallow model\n",
    "# LGBM\n",
    "init_kwargs = {'objective': 'regression', 'n_estimators': 100, 'n_jobs': n_jobs, 'random_state': SEED}    \n",
    "lgbm = lgb.LGBMModel(**init_kwargs)\n",
    "\n",
    "# Train\n",
    "fit_kwargs = {'verbose': verbose}\n",
    "t0 = time()\n",
    "lgbm.fit(xvl_fea, yvl, **fit_kwargs)\n",
    "print('Train time: {:.2f} mins'.format( (time()-t0)/60 ))\n",
    "\n",
    "# Predict\n",
    "pred_yvl = lgbm.predict(xvl_fea)\n",
    "\n",
    "# Calc scores\n",
    "fea_ext_scores = {}\n",
    "fea_ext_scores['r2'] = r2_score(yvl, pred_yvl)\n",
    "fea_ext_scores['mae'] = mean_absolute_error(yvl, pred_yvl)\n",
    "print(fea_ext_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create mini Top6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_parquet(datapath, engine='auto', columns=None)\n",
    "# data = data.sample(frac=1.0, axis=0, random_state=SEED).reset_index(drop=True)\n",
    "# print(data.shape)\n",
    "\n",
    "# col_idx = data.nunique(dropna=True).values == 1  # col indexes to drop\n",
    "# data = data.iloc[:, ~col_idx]\n",
    "# print(data.shape)\n",
    "\n",
    "# def subset(data, s):\n",
    "#     if s <= 1.0:\n",
    "#         data_size = int(data.shape[0]*s)\n",
    "#     return data[:data_size]\n",
    "\n",
    "# data = subset(data, s=0.3)\n",
    "# print(data.shape)\n",
    "# # data.to_csv(datadir/'uniq.top6.reg.mini.csv', index=False)\n",
    "# data.to_parquet(datadir/'uniq.top6.reg.mini.parquet', index=False)\n",
    "\n",
    "# display(data[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85501, 3763)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "# data = pd.read_csv(datadir/'uniq.top6.reg.mini.csv')\n",
    "data = pd.read_parquet(datadir/'uniq.top6.reg.mini.parquet')\n",
    "print(data.shape)\n",
    "\n",
    "if 'topNcode' in str(datadir):\n",
    "    data.drop(columns=['CELL', 'DRUG'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68400, 3761)\n",
      "(17101, 3761)\n"
     ]
    }
   ],
   "source": [
    "# Split train/test\n",
    "df_tr, df_vl = train_test_split(data, test_size=0.2)\n",
    "df_tr = df_tr.reset_index(drop=True)\n",
    "df_vl = df_vl.reset_index(drop=True)\n",
    "print(df_tr.shape)\n",
    "print(df_vl.shape)\n",
    "\n",
    "# Split features/target\n",
    "ytr, xtr = df_tr.iloc[:,0], df_tr.iloc[:,1:]\n",
    "yvl, xvl = df_vl.iloc[:,0], df_vl.iloc[:,1:]\n",
    "\n",
    "del data, df_tr, df_vl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68400, 3760) (68400,)\n",
      "(17101, 3760) (17101,)\n"
     ]
    }
   ],
   "source": [
    "# Scale\n",
    "col = xtr.columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "xtr = pd.DataFrame( scaler.fit_transform(xtr), columns=col ).astype(np.float32)\n",
    "xvl = pd.DataFrame( scaler.transform(xvl), columns=col ).astype(np.float32)\n",
    "\n",
    "print(xtr.shape, ytr.shape)\n",
    "print(xvl.shape, yvl.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "https://nbviewer.jupyter.org/github/FraPochetti/KagglePlaygrounds/blob/master/NYC%20Taxi%20Fares%20Prediction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Simple example\n",
    "\n",
    "# x = torch.Tensor([[1, 2, 3], [1, 2, 3]]).view(-1, 2)\n",
    "# y = torch.Tensor([[2, 1]]).view(2, -1)\n",
    "\n",
    "# print('x.shape', x.shape)\n",
    "# print('y.shape', y.shape)\n",
    "\n",
    "# print('\\nx\\n', x)\n",
    "# print('\\ny\\n', y)\n",
    "# print('\\nx * y\\n', torch.mm(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetTidy(Dataset):\n",
    "    # discuss.pytorch.org/t/data-processing-as-a-batch-way/14154\n",
    "    # github.com/utkuozbulak/pytorch-custom-dataset-examples#incorporating-pandas\n",
    "    # nbviewer.jupyter.org/github/FraPochetti/KagglePlaygrounds/blob/master/NYC%20Taxi%20Fares%20Prediction.ipynb\n",
    "    def __init__(self,\n",
    "                 X: pd.DataFrame,\n",
    "                 Y: pd.DataFrame):\n",
    "        # xdata and ydata are pandas dfs\n",
    "        X = pd.DataFrame(X).values\n",
    "        Y = pd.DataFrame(Y).values\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.Y = torch.tensor(Y, dtype=torch.float32)\n",
    "        self.Y = self.Y.view(-1, 1)\n",
    "        \n",
    "        # xdata and ydata are torch tensors\n",
    "        #self.x = xdata\n",
    "        #self.y = ydata\n",
    "        #self.y = self.y.view(-1, 1)        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X[idx, :]\n",
    "        Y = self.Y[idx]\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_ds = DatasetTidy(X=xtr, Y=ytr)\n",
    "vl_ds = DatasetTidy(X=xvl, Y=yvl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loaders\n",
    "batch_size = 32\n",
    "num_workers = 1\n",
    "tr_loader_kwargs = {'batch_size': batch_size, 'shuffle': True, 'num_workers': num_workers}\n",
    "vl_loader_kwargs = {'batch_size': 4*batch_size, 'shuffle': False, 'num_workers': num_workers}\n",
    "\n",
    "tr_loader = DataLoader(tr_ds, **tr_loader_kwargs)\n",
    "vl_loader = DataLoader(vl_ds, **vl_loader_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xb, yb = next(iter(tr_loader))\n",
    "# print(xb.shape, yb.shape)\n",
    "# print(xb[:2])\n",
    "# print(yb[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NN_REG(nn.Module):\n",
    "#     def __init__(self, input_dim):\n",
    "#         super().__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, 1000)\n",
    "#         self.fc2 = nn.Linear(1000, 1000)\n",
    "#         self.fc3 = nn.Linear(1000, 500)\n",
    "#         self.fc4 = nn.Linear(500, 250)\n",
    "#         self.fc5 = nn.Linear(250, 125)\n",
    "#         self.fc6 = nn.Linear(125, 60)\n",
    "#         self.fc7 = nn.Linear(60, 30)\n",
    "#         self.fc8 = nn.Linear(30, 1)\n",
    "#         self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.dropout(F.relu(self.fc1(x)))\n",
    "#         x = self.dropout(F.relu(self.fc2(x)))\n",
    "#         x = self.dropout(F.relu(self.fc3(x)))\n",
    "#         x = self.dropout(F.relu(self.fc4(x)))\n",
    "#         x = self.dropout(F.relu(self.fc5(x)))\n",
    "#         x = self.dropout(F.relu(self.fc6(x)))\n",
    "#         x = self.dropout(F.relu(self.fc7(x)))\n",
    "#         x = F.relu(self.fc8(x))\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_REG(nn.Module):\n",
    "    def __init__(self, input_dim, dr_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 500)\n",
    "        self.fc3 = nn.Linear(500, 250)\n",
    "        self.fc4 = nn.Linear(250, 60)\n",
    "        self.fc5 = nn.Linear(60, 1)\n",
    "        self.dropout = nn.Dropout(dr_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = self.dropout(F.relu(self.fc4(x)))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init_linear(m: nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch initializes the layers by default (e.g., Linear uses kaiming_uniform_)\n",
    "    www.deeplearningwizard.com/deep_learning/boosting_models_pytorch/weight_initialization_activation_functions/\n",
    "    stackoverflow.com/questions/49433936/how-to-initialize-weights-in-pytorch\n",
    "    github.com/xduan7/UnoPytorch/blob/master/networks/initialization/weight_init.py\n",
    "    \"\"\"\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model to CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_device(model):\n",
    "    return str(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_available:   True\n",
      "device_name:    GeForce RTX 2080 Ti\n",
      "device_count:   4\n",
      "current_device: 0\n"
     ]
    }
   ],
   "source": [
    "# pytorch.org/docs/stable/cuda.html\n",
    "# towardsdatascience.com/speed-up-your-algorithms-part-1-pytorch-56d8a4ae7051\n",
    "print('is_available:  ', torch.cuda.is_available())\n",
    "print('device_name:   ', torch.cuda.get_device_name(0))\n",
    "print('device_count:  ', torch.cuda.device_count())\n",
    "print('current_device:', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n",
      "current_device: 0\n"
     ]
    }
   ],
   "source": [
    "# Choose device\n",
    "device = torch.device('cuda:3')\n",
    "\n",
    "# Move model to CUDA device\n",
    "model = NN_REG(input_dim=tr_ds.X.shape[1]).to(device) # send model to gpu/cpu device\n",
    "model.apply(weight_init_linear)\n",
    "\n",
    "# Query device where the model is located\n",
    "print(get_model_device(model))\n",
    "print('current_device:', torch.cuda.current_device()) # why current device is 0??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if device.type == 'cuda':\n",
    "#     print(get_model_device(model))\n",
    "#     print('Memory Usage:')\n",
    "#     print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3, 1), 'GB')\n",
    "#     print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3, 1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Choose cuda device with context manager\n",
    "# with torch.cuda.device(2):\n",
    "#     print('\\ncurrent_device:', torch.cuda.current_device())\n",
    "#     model = NN_REG(input_dim=tr_ds.x.shape[1]).to(device=device)\n",
    "# print('current_device:', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fnc = nn.MSELoss(reduction='mean')\n",
    "opt = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)  # pytorch.org/docs/stable/optim.html\n",
    "# lr_scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer=opt, base_lr=1e-5, max_lr=1e-3, mode='triangular')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a single training iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx, yy = next(iter(tr_loader))\n",
    "# xx = xx.to(device)\n",
    "# yy = yy.to(device)\n",
    "# print(xx.device)\n",
    "# print(yy.device)\n",
    "\n",
    "# # Forward\n",
    "# opt.zero_grad()\n",
    "# pred = model(xx)\n",
    "\n",
    "# print(f'pred.shape {pred.shape}')\n",
    "# print(f'yb.shape {yy.shape}')\n",
    "# yy = yy.view(pred.shape)\n",
    "# print(f'yb.shape {yy.shape}\\n')\n",
    "\n",
    "# print('pred:\\n', pred[:3])\n",
    "# print('yy:\\n', yy[:3])\n",
    "# pred = pred.type(torch.float32)\n",
    "# print('pred:\\n', pred[:3])\n",
    "\n",
    "# # Backprop\n",
    "# loss = loss_fnc(pred, yy)\n",
    "# loss.backward() # compute loss gradients wrt to model parameters and inputs\n",
    "# opt.step()      # update model parameters;  pytorch.org/docs/stable/optim.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'pred.shape {pred.shape}')\n",
    "# print(f'yb.shape   {yb.shape}\\n')\n",
    "# mae = torch.abs(pred - yb)\n",
    "# r2_torch(y_true=yb, y_pred=pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discuss.pytorch.org/t/what-does-torch-backends-cudnn-benchmark-do/5936\n",
    "# groups.google.com/forum/#!topic/torch7/CkB57025yRY\n",
    "# torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_torch(y_true, y_pred):\n",
    "    epsilon = 1e-7  # this epsilon value used in TF\n",
    "    SS_res = torch.sum( (y_true - y_pred)**2 )\n",
    "    SS_tot = torch.sum( (y_true - torch.mean(y_true))**2 )\n",
    "    r2 = 1 - SS_res / (SS_tot + epsilon)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def calc_reg_scores(pred, true, metrics, val=False):\n",
    "#     prfx = 'val_' if val is True else '' \n",
    "#     scores = {}\n",
    "    \n",
    "#     for m in metrics:\n",
    "#         if 'loss' in m:\n",
    "#             continue\n",
    "            \n",
    "#         elif m in ['mean_abs_err', 'mean_absolute_error']:\n",
    "#             scores[prfx + 'mean_abs_err'] = torch.mean(torch.abs(pred-true))\n",
    "\n",
    "#         elif m in ['median_abs_err', 'median_absolute_error']:\n",
    "#             scores[prfx + 'median_abs_err'] = torch.median(torch.abs(pred-true))\n",
    "\n",
    "#         elif m in ['mean_sqrd_err', 'mean_squared_error']:\n",
    "#             scores[prfx + 'mean_sqrd_err'] = torch.mean(torch.pow(pred-true, 0.5))  # or torch.mean(torch.sqrt(pred-true))\n",
    "            \n",
    "#         elif m in ['r2', 'r2_score']:\n",
    "#             scores[prfx + 'r2'] = r2_torch(y_true=true, y_pred=pred)\n",
    "            \n",
    "#     return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_scores_reg(pred, true, scores):\n",
    "    \"\"\" Updates score metrics for regression ML predictions.\n",
    "    The scores are summed for every call of the function (single func call corresponds a single batch).\n",
    "    \n",
    "    Note: these must be implemented with pytroch commands! Otherwise, results gives error:\n",
    "    RuntimeError: Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead.   \n",
    "    pred, true = pred.numpy(), yy.numpy()\n",
    "    tr_mae += sklearn.metrics.mean_absolute_error(true, pred)\n",
    "    tr_r2 += sklearn.metrics.r2_score(true, pred)\n",
    "    \"\"\"\n",
    "    for m in scores.keys():\n",
    "        if 'loss' in m:\n",
    "            continue\n",
    "            \n",
    "        elif any([True if v in m else False for v in ['mean_abs_err', 'mean_absolute_error']]):\n",
    "            scores[m] += torch.mean( torch.abs(pred-true) ).item()\n",
    "\n",
    "        elif any([True if v in m else False for v in ['median_abs_err', 'median_absolute_error']]):\n",
    "            scores[m] += torch.median( torch.abs(pred-true) ).item()\n",
    "\n",
    "        elif any([True if v in m else False for v in ['mean_sqrd_err', 'mean_squared_error']]):\n",
    "            scores[m] += torch.mean( torch.pow(pred-true, 0.5) ).item()  # or torch.mean(torch.sqrt(pred-true))\n",
    "            \n",
    "        elif any([True if v in m else False for v in ['r2', 'r2_score']]):\n",
    "            scores[m] += r2_torch(y_true=true, y_pred=pred).item()\n",
    "            \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_batch(x_dct, y, model, loss_fnc, opt=None):\n",
    "    \"\"\" \n",
    "    Args:\n",
    "        opt (torch.optim) : no backprop is performed if optimizer is not provided (for val or test) \n",
    "    \"\"\"    \n",
    "    pred = model(**x_dct)\n",
    "    pred = pred.type(y.dtype)\n",
    "    loss = loss_fnc(pred, y)\n",
    "    \n",
    "    # Backward pass\n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "    return loss, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model: nn.Module,\n",
    "        loss_fnc,\n",
    "        opt: torch.optim,\n",
    "        tr_dl: torch.utils.data.DataLoader,\n",
    "        vl_dl: torch.utils.data.DataLoader=None,\n",
    "        epochs: int=1,\n",
    "        device: torch.device='cuda:0',\n",
    "        verbose: bool=True,\n",
    "        metrics=[]) -> dict:\n",
    "    \"\"\" github.com/stared/livelossplot/blob/master/examples/pytorch.ipynb\n",
    "    Args:\n",
    "        metrics (list) : list of metric scores to log\n",
    "            (available metrics: 'mean_abs_err','median_abs_err', 'mean_sqrd_err', 'r2)\n",
    "    \"\"\" \n",
    "    # Create dicts to log scores\n",
    "    if vl_dl is None:\n",
    "        logs = OrderedDict({'loss': []})\n",
    "        logs.update(OrderedDict({m: [] for m in metrics}))        \n",
    "    else:\n",
    "        logs = OrderedDict({'loss': [], 'val_loss': []})\n",
    "        for m in metrics: logs.update(OrderedDict({m: [], 'val_'+m: []}))\n",
    "    \n",
    "    # Iter over epochs\n",
    "    phases = ['train', 'val'] if vl_dl is not None else ['train']\n",
    "    for ep in range(epochs):\n",
    "        ep_t0 = time()\n",
    "        # lr_scheduler.step()\n",
    "        \n",
    "        for ph in phases:\n",
    "            if ph == 'train':\n",
    "                model.train()\n",
    "                dl = tr_dl\n",
    "                scores = {m: 0 for m in logs.keys() if 'val' not in m}\n",
    "                loss_name = 'loss'\n",
    "            elif ph == 'val':\n",
    "                model.eval()\n",
    "                dl = vl_dl\n",
    "                scores = {m: 0 for m in logs.keys() if 'val' in m}\n",
    "                loss_name = 'val_loss'\n",
    "\n",
    "            # Iter over batches\n",
    "            for x, y in dl:\n",
    "                y = y.to(device)\n",
    "                x = x.to(device)\n",
    "                x_dct = {'x': x} # new\n",
    "                \n",
    "                # Process batch\n",
    "                if ph == 'train':\n",
    "                    loss, pred = proc_batch(x_dct, y, model=model, loss_fnc=loss_fnc, opt=opt)\n",
    "                else:\n",
    "                    loss, pred = proc_batch(x_dct, y, model=model, loss_fnc=loss_fnc, opt=None)\n",
    "\n",
    "                # Compute metrics (running avg)\n",
    "                scores[loss_name] += loss.item()\n",
    "                scores = update_scores_reg(pred=pred, true=y, scores=scores)\n",
    "            \n",
    "            # Log scores\n",
    "            for m in scores.keys():\n",
    "                logs[m].append(scores[m]/len(dl))\n",
    "            \n",
    "        del x, y, loss, pred, scores\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'Epoch {ep+1}/{epochs}; ',\n",
    "                  f'{int(time()-ep_t0)}s; ',\n",
    "                  [f'{k}: {v[-1]:.3f}' for k, v in logs.items()])\n",
    "            \n",
    "        # TODO: log scores into file\n",
    "\n",
    "    return model, logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "metrics = ['mean_abs_err', 'r2']\n",
    "verbose = False\n",
    "fit_kwargs = {'epochs': epochs, 'device': device, 'metrics': metrics, 'verbose': verbose}\n",
    "\n",
    "t0 = time()\n",
    "base_model, logs = fit(model = model,\n",
    "                       loss_fnc = loss_fnc,\n",
    "                       opt = opt,\n",
    "                       tr_dl = tr_loader,\n",
    "                       vl_dl = vl_loader,\n",
    "                       **fit_kwargs)\n",
    "print('{}'.format( (time()-t0)/60 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline methods:\n",
    "\n",
    "1. Train model from scratch on tf set\n",
    "2. Predict on the tf set\n",
    "\n",
    "Transfer learning methods:\n",
    "1. Freeze all layers, and reinitialize the last n layers (n=1, 2, ...)\n",
    "2. Freeze all layers, and finetune the last n layers (n=1, 2, ...)\n",
    "3. Freeze all layers, fea extract for tf, and then supply the extracted fea to LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, fea_extract):\n",
    "    if fea_extract:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model_grad(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        print('{} grad: {}'.format(name, param.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 1 (train from scratch xvl) --> need CV scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_kwargs = {'objective': 'regression', 'n_estimators': 100, 'n_jobs': n_jobs, 'random_state': SEED}    \n",
    "# b1_model = lgb.LGBMModel(**init_kwargs)\n",
    "\n",
    "# # Train\n",
    "# b1_model.fit(xvl, yvl)\n",
    "\n",
    "# # Predict\n",
    "# pred_yvl = b1_model.predict(xvl)\n",
    "\n",
    "# # Scores\n",
    "# b1_scores = {}\n",
    "# b1_scores['r2_vl'] = r2_score(yvl, pred_yvl)\n",
    "# b1_scores['mae_vl'] = mean_absolute_error(yvl, pred_yvl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b1_model = NN_REG(input_dim=vl_ds.x.shape[1]).to(device) # send model to gpu/cpu device\n",
    "# b1_model.apply(weight_init_linear)\n",
    "\n",
    "# epochs = 20\n",
    "# metrics = ['mean_abs_err', 'r2']\n",
    "# verbose = False\n",
    "# fit_kwargs = {'epochs': epochs, 'device': device, 'metrics': metrics, 'verbose': verbose}\n",
    "\n",
    "# # Train\n",
    "# t0 = time()\n",
    "# b1_model, logs = fit(model = b1_model,\n",
    "#                      loss_fnc = loss_fnc,\n",
    "#                      opt = opt_ft,\n",
    "#                      tr_dl = trnsf_loader,\n",
    "#                      **fit_kwargs)\n",
    "# print('{} mins'.format( (time()-t0)/60 ))\n",
    "\n",
    "# # Predict\n",
    "# pass\n",
    "\n",
    "# # Scores\n",
    "# b1_scores = {}\n",
    "# b1_scores['r2_vl'] = r2_score(yvl, pred_yvl)\n",
    "# b1_scores['mae_vl'] = mean_absolute_error(yvl, pred_yvl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 2 (predict xvl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_scores(m, x, y):\n",
    "    x = torch.tensor(x.values, requires_grad=False, dtype=torch.float32).to(device)\n",
    "    pred = m(x).cpu().detach().numpy()\n",
    "    scores = {}\n",
    "    scores['r2'] = r2_score(y, pred)\n",
    "    scores['mae'] = mean_absolute_error(y, pred)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mae_vl': 0.09317579840885173, 'r2_vl': 0.3403574532179806}\n"
     ]
    }
   ],
   "source": [
    "# xtr_torch = torch.tensor(xtr.values, requires_grad=False, dtype=torch.float32).to(device)\n",
    "xvl_torch = torch.tensor(xvl.values, requires_grad=False, dtype=torch.float32).to(device)\n",
    "\n",
    "# Predict\n",
    "# pred_ytr = model(xtr_torch).cpu().detach().numpy()\n",
    "pred_yvl = base_model(xvl_torch).cpu().detach().numpy()\n",
    "\n",
    "# Scores\n",
    "b2_scores = {}\n",
    "# b2_scores['r2_tr'] = r2_score(ytr, pred_ytr)\n",
    "b2_scores['r2_vl'] = r2_score(yvl, pred_yvl)\n",
    "# b2_scores['mae_tr'] = mean_absolute_error(ytr, pred_ytr)\n",
    "b2_scores['mae_vl'] = mean_absolute_error(yvl, pred_yvl)\n",
    "\n",
    "pprint(b2_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learn 1 (freeze all; reinitialize last *n*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight grad: True\n",
      "fc1.bias grad: True\n",
      "fc2.weight grad: True\n",
      "fc2.bias grad: True\n",
      "fc3.weight grad: True\n",
      "fc3.bias grad: True\n",
      "fc4.weight grad: True\n",
      "fc4.bias grad: True\n",
      "fc5.weight grad: True\n",
      "fc5.bias grad: True\n"
     ]
    }
   ],
   "source": [
    "check_model_grad(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers, and reinitialize the last layer\n",
    "fea_extract = True\n",
    "model_ft = copy.deepcopy(base_model)\n",
    "\n",
    "set_parameter_requires_grad(model_ft, fea_extract)\n",
    "\n",
    "model_ft.fc5 = nn.Linear(model_ft.fc5.in_features, model_ft.fc5.out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight grad: False\n",
      "fc1.bias grad: False\n",
      "fc2.weight grad: False\n",
      "fc2.bias grad: False\n",
      "fc3.weight grad: False\n",
      "fc3.bias grad: False\n",
      "fc4.weight grad: False\n",
      "fc4.bias grad: False\n",
      "fc5.weight grad: True\n",
      "fc5.bias grad: True\n"
     ]
    }
   ],
   "source": [
    "check_model_grad(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the old model to compare weights later (make sure that the frozed layers stay unchanged)\n",
    "model_ft_old = copy.deepcopy(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0306, -0.0024, -0.0440, -0.0927, -0.0622,  0.0093,  0.0598, -0.0715,\n",
       "         -0.1164,  0.1261,  0.0054,  0.0346,  0.1018, -0.1051,  0.0793, -0.1260,\n",
       "          0.1151,  0.1185,  0.0354,  0.0446, -0.0551, -0.0308, -0.0680,  0.0981,\n",
       "          0.0890, -0.0649,  0.0451, -0.0464, -0.0915,  0.0737, -0.0213, -0.0230,\n",
       "          0.0936,  0.0543,  0.0761,  0.0776, -0.0152, -0.1106,  0.0751, -0.0411,\n",
       "         -0.0245,  0.0010,  0.0429,  0.1153, -0.0590,  0.0163, -0.0392,  0.0539,\n",
       "         -0.0837, -0.0567, -0.0109, -0.0303,  0.0376,  0.0332, -0.0507, -0.1164,\n",
       "          0.0029,  0.0363,  0.1094,  0.0071]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.fc5.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0306, -0.0024, -0.0440, -0.0927, -0.0622,  0.0093,  0.0598, -0.0715,\n",
       "         -0.1164,  0.1261,  0.0054,  0.0346,  0.1018, -0.1051,  0.0793, -0.1260,\n",
       "          0.1151,  0.1185,  0.0354,  0.0446, -0.0551, -0.0308, -0.0680,  0.0981,\n",
       "          0.0890, -0.0649,  0.0451, -0.0464, -0.0915,  0.0737, -0.0213, -0.0230,\n",
       "          0.0936,  0.0543,  0.0761,  0.0776, -0.0152, -0.1106,  0.0751, -0.0411,\n",
       "         -0.0245,  0.0010,  0.0429,  0.1153, -0.0590,  0.0163, -0.0392,  0.0539,\n",
       "         -0.0837, -0.0567, -0.0109, -0.0303,  0.0376,  0.0332, -0.0507, -0.1164,\n",
       "          0.0029,  0.0363,  0.1094,  0.0071]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft_old.fc5.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "ft_ds = DatasetTidy(X=xvl, Y=yvl)\n",
    "# ft_ds = ds_vl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "batch_size = 32\n",
    "num_workers = 1\n",
    "ft_loader_kwargs = {'batch_size': batch_size, 'shuffle': True, 'num_workers': num_workers}\n",
    "# vl_loader_kwargs = {'batch_size': 4*batch_size, 'shuffle': False, 'num_workers': num_workers}\n",
    "\n",
    "ft_loader = DataLoader(ft_ds, **ft_loader_kwargs)\n",
    "# vl_loader = DataLoader(vl_ds, **vl_loader_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc5.weight\n",
      "\t fc5.bias\n"
     ]
    }
   ],
   "source": [
    "# Create optimizer that updates the desired parameters.\n",
    "\n",
    "# We make a list of such parameters and input this list to the SGD algorithm constructor.\n",
    "# To verify this, check out the printed parameters to learn. When finetuning, this list should be long\n",
    "# and include all of the model parameters. However, when feature extracting this list should be short\n",
    "# and only include the weights and biases of the reshaped layers.\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True\n",
    "\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if fea_extract:\n",
    "    params_to_update = []\n",
    "    for name, param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name, param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "opt_ft = optim.SGD(params_to_update, lr=1e-4, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "metrics = ['mean_abs_err', 'r2']\n",
    "verbose = False\n",
    "fit_kwargs = {'epochs': epochs, 'device': device, 'metrics': metrics, 'verbose': verbose}\n",
    "\n",
    "model_ft, logs = fit(model = model_ft,\n",
    "                     loss_fnc = loss_fnc,\n",
    "                     opt = opt_ft,\n",
    "                     tr_dl = ft_loader,\n",
    "                     vl_dl = None,\n",
    "                     **fit_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mae_vl': 0.09364312459260747, 'r2_vl': 0.28525338764636476}\n"
     ]
    }
   ],
   "source": [
    "xvl_torch = torch.tensor(xvl.values, requires_grad=False, dtype=torch.float32).to(device)\n",
    "pred_yvl = model_ft(xvl_torch).cpu().detach().numpy()\n",
    "\n",
    "t_scores1 = {}\n",
    "t_scores1['r2_vl'] = r2_score(yvl, pred_yvl)\n",
    "t_scores1['mae_vl'] = mean_absolute_error(yvl, pred_yvl)\n",
    "\n",
    "pprint(t_scores1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why this doesn't work ?!\n",
    "# print(next(model_ft_old.named_parameters()))\n",
    "# print(next(model_ft.named_parameters()))\n",
    "# torch.allclose(model_ft_old.fc5.weight, model_ft.fc5.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0306, -0.0024, -0.0440, -0.0927, -0.0622,  0.0093,  0.0598, -0.0715,\n",
       "         -0.1164,  0.1261,  0.0054,  0.0346,  0.1018, -0.1051,  0.0793, -0.1260,\n",
       "          0.1151,  0.1185,  0.0354,  0.0446, -0.0551, -0.0308, -0.0680,  0.0981,\n",
       "          0.0890, -0.0649,  0.0451, -0.0464, -0.0915,  0.0737, -0.0213, -0.0230,\n",
       "          0.0936,  0.0543,  0.0761,  0.0776, -0.0152, -0.1106,  0.0751, -0.0411,\n",
       "         -0.0245,  0.0010,  0.0429,  0.1153, -0.0590,  0.0163, -0.0392,  0.0539,\n",
       "         -0.0837, -0.0567, -0.0109, -0.0303,  0.0376,  0.0332, -0.0507, -0.1164,\n",
       "          0.0029,  0.0363,  0.1094,  0.0071]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_ft_old.fc5.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0322, -0.0027,  0.0077, -0.0810, -0.0611,  0.0099,  0.0602, -0.0682,\n",
       "         -0.1152,  0.1215,  0.0191,  0.0389,  0.0691, -0.0508,  0.0792,  0.0170,\n",
       "          0.0005,  0.1183,  0.0345,  0.0458,  0.0092, -0.0090, -0.0205,  0.0980,\n",
       "          0.0176, -0.0649,  0.0110, -0.0458,  0.0185,  0.0738,  0.0144, -0.0144,\n",
       "          0.0141,  0.0186,  0.0759,  0.0763, -0.0124, -0.0475,  0.0752, -0.0408,\n",
       "          0.0169,  0.0067,  0.0095,  0.1149, -0.0568,  0.0212, -0.0383, -0.0617,\n",
       "         -0.0816,  0.0110, -0.0109, -0.0305,  0.0109,  0.0093, -0.0492, -0.1154,\n",
       "          0.0197,  0.0363,  0.1059,  0.0078]], device='cuda:3')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.fc5.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learn 2 (freeze all, finetune last *n*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight grad: True\n",
      "fc1.bias grad: True\n",
      "fc2.weight grad: True\n",
      "fc2.bias grad: True\n",
      "fc3.weight grad: True\n",
      "fc3.bias grad: True\n",
      "fc4.weight grad: True\n",
      "fc4.bias grad: True\n",
      "fc5.weight grad: True\n",
      "fc5.bias grad: True\n"
     ]
    }
   ],
   "source": [
    "check_model_grad(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers, and reinitialize the last layer\n",
    "fea_extract = True\n",
    "model_ft = copy.deepcopy(base_model)\n",
    "set_parameter_requires_grad(model_ft, fea_extract)\n",
    "# model_ft.fc5 = nn.Linear(model_ft.fc5.in_features, model_ft.fc5.out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight grad: False\n",
      "fc1.bias grad: False\n",
      "fc2.weight grad: False\n",
      "fc2.bias grad: False\n",
      "fc3.weight grad: False\n",
      "fc3.bias grad: False\n",
      "fc4.weight grad: False\n",
      "fc4.bias grad: False\n",
      "fc5.weight grad: False\n",
      "fc5.bias grad: False\n"
     ]
    }
   ],
   "source": [
    "check_model_grad(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(model_ft.fc5.parameters()).requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model_ft.named_parameters():\n",
    "    if 'fc5' in name:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight grad: False\n",
      "fc1.bias grad: False\n",
      "fc2.weight grad: False\n",
      "fc2.bias grad: False\n",
      "fc3.weight grad: False\n",
      "fc3.bias grad: False\n",
      "fc4.weight grad: False\n",
      "fc4.bias grad: False\n",
      "fc5.weight grad: True\n",
      "fc5.bias grad: True\n"
     ]
    }
   ],
   "source": [
    "check_model_grad(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "metrics = ['mean_abs_err', 'r2']\n",
    "verbose = False\n",
    "fit_kwargs = {'epochs': epochs, 'device': device, 'metrics': metrics, 'verbose': verbose}\n",
    "\n",
    "model_ft, logs = fit(model = model_ft,\n",
    "                     loss_fnc = loss_fnc,\n",
    "                     opt = opt_ft,\n",
    "                     tr_dl = ft_loader,\n",
    "                     vl_dl = None,\n",
    "                     **fit_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mae_vl': 0.09390004824685616, 'r2_vl': 0.2826980408904164}\n"
     ]
    }
   ],
   "source": [
    "xvl_torch = torch.tensor(xvl.values, requires_grad=False, dtype=torch.float32).to(device)\n",
    "pred_yvl = model_ft(xvl_torch).cpu().detach().numpy()\n",
    "\n",
    "t_scores2 = {}\n",
    "t_scores2['r2_vl'] = r2_score(yvl, pred_yvl)\n",
    "t_scores2['mae_vl'] = mean_absolute_error(yvl, pred_yvl)\n",
    "\n",
    "pprint(t_scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learn 3 (freeze all, extract fea; train with LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = pd.DataFrame(logs).reset_index().rename(columns={'index': 'epoch'})\n",
    "logs['epoch'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "skp_ep = 5\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "# plt.plot(logs['loss'], label='loss');\n",
    "# plt.plot(logs['val_loss'], label='val_loss');\n",
    "# plt.legend(loc='best');\n",
    "\n",
    "# plt.plot(logs['mean_abs_err'], label='mean_abs_err');\n",
    "# plt.plot(logs['val_mean_abs_err'], label='val_mean_abs_err');\n",
    "# plt.legend(loc='best');\n",
    "\n",
    "m = 'r2'\n",
    "plt.plot(logs[m][skp_ep:], label=m);\n",
    "plt.plot(logs[f'val_{m}'][skp_ep:], label=f'val_{m}');\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='best');\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit(model: nn.Module,\n",
    "#         loss_fnc,\n",
    "#         opt: torch.optim,\n",
    "#         tr_dl: torch.utils.data.DataLoader,\n",
    "#         vl_dl: torch.utils.data.DataLoader=None,\n",
    "#         epochs: int=1,\n",
    "#         device: torch.device='cuda:0',\n",
    "#         verbose: bool=True,\n",
    "#         metrics=[]) -> dict:\n",
    "#     \"\"\" github.com/stared/livelossplot/blob/master/examples/pytorch.ipynb\n",
    "#     Args:\n",
    "#         metrics (list) : list of metric scores to log\n",
    "#             (available metrics: 'mean_abs_err','median_abs_err', 'mean_sqrd_err', 'r2)\n",
    "#     \"\"\" \n",
    "#     print(f'Arg `device`: {device}')\n",
    "#     model.to(device)\n",
    "#     print('current_device:', torch.cuda.current_device())\n",
    "    \n",
    "#     # Choose cuda device with context manager --> try using context manager!!!\n",
    "#     # with torch.cuda.device(device):\n",
    "        \n",
    "#     # Create dicts to log scores\n",
    "#     if vl_dl is None:\n",
    "#         logs = OrderedDict({'loss': []})\n",
    "#         logs.update(OrderedDict({m: [] for m in metrics}))        \n",
    "#     else:\n",
    "#         logs = OrderedDict({'loss': [], 'val_loss': []})\n",
    "#         for m in metrics: logs.update(OrderedDict({m: [], 'val_'+m: []}))\n",
    "    \n",
    "#     # Iter over epochs\n",
    "#     phases = ['train', 'val'] if vl_dl is not None else ['train']\n",
    "#     for ep in range(epochs):\n",
    "#         ep_t0 = time()\n",
    "        \n",
    "#         # -------------\n",
    "#         # Training loop\n",
    "#         # -------------\n",
    "#         model.train() # turns-on dropout for training\n",
    "#         tr_scores = {m: 0 for m in logs.keys() if 'val' not in m}\n",
    "        \n",
    "#         for xx, yy in tr_dl:\n",
    "#             xx = xx.to(device)\n",
    "#             yy = yy.to(device)\n",
    "            \n",
    "#             # Process batch\n",
    "#             loss, pred = proc_batch(xx, yy, model, loss_fnc, opt=opt)\n",
    "                  \n",
    "#             # Compute metrics (running avg)\n",
    "#             tr_scores['loss'] += loss.item()\n",
    "#             tr_scores = update_scores_reg(pred=pred, true=yy, scores=tr_scores)\n",
    "                \n",
    "#         for m in tr_scores.keys():\n",
    "#             print(m)\n",
    "#             logs[m].append(tr_scores[m]/len(tr_dl))\n",
    "                \n",
    "#         del xx, yy, loss, pred, tr_scores\n",
    "                \n",
    "#         # ---------------\n",
    "#         # Validation loop\n",
    "#         # ---------------        \n",
    "#         if vl_dl is not None:\n",
    "#             model.eval()  # turn-off dropout in inferenece\n",
    "#             vl_scores = {m: 0 for m in logs.keys() if 'val' in m}\n",
    "            \n",
    "#             with torch.no_grad():\n",
    "#                 for xx, yy in vl_dl:\n",
    "#                     xx = xx.to(device)\n",
    "#                     yy = yy.to(device)\n",
    "                    \n",
    "#                     # Process batch\n",
    "#                     loss, pred = proc_batch(xx, yy, model, loss_fnc, opt=None)\n",
    "                                \n",
    "#                     # Compute metrics at the end of each epoch (not the running avg across the batches)\n",
    "#                     vl_scores['val_loss'] += loss.item()\n",
    "#                     vl_scores = update_scores_reg(pred=pred, true=yy, scores=vl_scores)\n",
    "                        \n",
    "#                 # Update logs\n",
    "#                 for m in vl_scores.keys():\n",
    "#                     print(m)\n",
    "#                     logs[m].append(vl_scores[m]/len(vl_dl))\n",
    "        \n",
    "#                 del xx, yy, loss, pred, vl_scores\n",
    "        \n",
    "#         if verbose:\n",
    "#             print(f'Epoch {ep+1}/{epochs}; ',\n",
    "#                   f'{int(time()-ep_t0)}s; ',\n",
    "#                   [f'{k}: {v[-1]:.3f}' for k, v in logs.items()])\n",
    "#     return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verbose = True\n",
    "# epochs = 10\n",
    "# logs = OrderedDict({'loss': [], 'val_loss': [],\n",
    "#                     'mean_abs_err': [], 'val_mean_abs_err': [],\n",
    "#                     'r2': [], 'val_r2': []})\n",
    "\n",
    "# # Choose cuda device with context manager\n",
    "# with torch.cuda.device(device):\n",
    "#     print('\\ncurrent_device:', torch.cuda.current_device())\n",
    "    \n",
    "#     for ep in range(epochs):\n",
    "#         ep_t0 = time()\n",
    "        \n",
    "#         # -------------\n",
    "#         # Training loop\n",
    "#         # -------------\n",
    "#         model.train() # turns-on dropout for training\n",
    "#         tr_loss, tr_mae, tr_r2 = 0, 0, 0\n",
    "\n",
    "#         for xx, yy in tr_loader:\n",
    "#             xx = xx.to(device) # move data to gpu/cpu device\n",
    "#             yy = yy.to(device) # move data to gpu/cpu device\n",
    "            \n",
    "#             # Feedforward\n",
    "#             pred = model(xx)\n",
    "#             loss = loss_fnc(pred, yy)\n",
    "\n",
    "#             # Backprop and optimization\n",
    "#             opt.zero_grad()\n",
    "#             loss.backward()   # compute loss gradients wrt to model parameters and inputs\n",
    "#             opt.step()  # update model parameters;  pytorch.org/docs/stable/optim.html\n",
    "            \n",
    "#             # Compute metrics\n",
    "#             tr_loss += loss.item() # item() returns a number from a tensor that contains a single value\n",
    "#             tr_mae += torch.mean(torch.abs(pred-yy))\n",
    "#             tr_r2 += r2_torch(y_true=yy, y_pred=pred)\n",
    "\n",
    "#         tr_loss /= len(tr_loader)\n",
    "#         tr_mae /= len(tr_loader)\n",
    "#         tr_r2 /= len(tr_loader)\n",
    "        \n",
    "#         logs['loss'].append(tr_loss)\n",
    "#         logs['mae'].append(tr_mae)\n",
    "#         logs['r2'].append(tr_r2)\n",
    "\n",
    "#         del xx, yy\n",
    "\n",
    "#         # ---------------\n",
    "#         # Validation loop\n",
    "#         # ---------------\n",
    "#         if vl_loader is not None:\n",
    "#             model.eval()  # turn-off dropout in inferenece\n",
    "#             with torch.no_grad():\n",
    "#                 vl_loss, vl_mae, vl_r2 = 0, 0, 0\n",
    "\n",
    "#                 for xx, yy in vl_loader:\n",
    "#                     xx = xx.to(device)\n",
    "#                     yy = yy.to(device)\n",
    "\n",
    "#                     # Feedforward\n",
    "#                     pred = model(xx)\n",
    "#                     loss = loss_fnc(pred, yy)\n",
    "\n",
    "#                     # Compute metrics\n",
    "#                     vl_loss += loss.item() # item() returns a number from a tensor that contains a single value\n",
    "#                     vl_mae += torch.mean(torch.abs(pred-yy))\n",
    "#                     vl_r2 += r2_torch(y_true=yy, y_pred=pred)\n",
    "\n",
    "#                 vl_loss /= len(vl_loader)\n",
    "#                 vl_mae /= len(vl_loader)\n",
    "#                 vl_r2 /= len(vl_loader)\n",
    "\n",
    "#                 logs['val_loss'].append(vl_loss)\n",
    "#                 logs['val_mae'].append(vl_mae)\n",
    "#                 logs['val_r2'].append(vl_r2)\n",
    "\n",
    "#                 del xx, yy\n",
    "\n",
    "# #         if verbose:\n",
    "# #             print(f'Epoch {ep+1}/{epochs}; ',\n",
    "# #                   f'{int(time()-t0)}s; '\n",
    "# #                   f'tr_loss: {tr_loss:.3f}; ',\n",
    "# #                   f'vl_loss: {vl_loss:.3f}; ',\n",
    "# #                   f'tr_mae: {tr_mae:.3f}; ',\n",
    "# #                   f'vl_mae: {vl_mae:.3f}; ',\n",
    "# #                   f'tr_r2: {tr_r2:.3f}; ',\n",
    "# #                   f'vl_r2: {vl_r2:.3f}; ')\n",
    "            \n",
    "#         if verbose:\n",
    "#             print(f'Epoch {ep+1}/{epochs}; ',\n",
    "#                   f'{int(time()-ep_t0)}s; ',\n",
    "#                   [f'{k}: {v[-1]:.3f}' for k, v in logs.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
