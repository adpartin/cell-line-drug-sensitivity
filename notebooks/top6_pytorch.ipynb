{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/xduan7/UnoPytorch/blob/master/uno_pytorch.py<br>\n",
    "https://github.com/xduan7/UnoPytorch/blob/master/networks/structures/response_net.py<br>\n",
    "https://github.com/xduan7/UnoPytorch/blob/master/networks/functions/resp_func.py<br>\n",
    "https://github.com/xduan7/UnoPytorch/blob/master/utils/datasets/drug_resp_dataset.py<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = Path('../data/raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create mini top6 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_parquet(datadir/'uniq.top6.reg.parquet', engine='auto', columns=None)\n",
    "# data = data.sample(frac=1.0, axis=0, random_state=SEED).reset_index(drop=True)\n",
    "# print(data.shape)\n",
    "\n",
    "# col_idx = data.nunique(dropna=True).values == 1  # col indexes to drop\n",
    "# data = data.iloc[:, ~col_idx]\n",
    "# print(data.shape)\n",
    "\n",
    "# def subset(data, s):\n",
    "#     if s <= 1.0:\n",
    "#         data_size = int(data.shape[0]*s)\n",
    "#     return data[:data_size]\n",
    "\n",
    "# data = subset(data, s=0.4)\n",
    "# print(data.shape)\n",
    "# data.to_csv(datadir/'uniq.top6.reg.mini.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and pre-process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113260, 3765)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(datadir/'uniq.top6.reg.mini.csv')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90608, 3765)\n",
      "(22652, 3765)\n"
     ]
    }
   ],
   "source": [
    "df_tr, df_te = train_test_split(data, test_size=0.2)\n",
    "df_tr = df_tr.reset_index(drop=True)\n",
    "df_te = df_te.reset_index(drop=True)\n",
    "print(df_tr.shape)\n",
    "print(df_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytr, xtr = df_tr.iloc[:,0], df_tr.iloc[:,1:]\n",
    "yte, xte = df_te.iloc[:,0], df_te.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale\n",
    "col_names = xtr.columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "xtr = pd.DataFrame( scaler.fit_transform(xtr) ).astype(np.float32)\n",
    "xte = pd.DataFrame( scaler.transform(xte) ).astype(np.float32)\n",
    "\n",
    "xtr.columns = col_names\n",
    "xte.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90608, 3764)\n",
      "(22652, 3764)\n",
      "(90608,)\n",
      "(22652,)\n"
     ]
    }
   ],
   "source": [
    "print(xtr.shape)\n",
    "print(xte.shape)\n",
    "print(ytr.shape)\n",
    "print(yte.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch\n",
    "https://nbviewer.jupyter.org/github/FraPochetti/KagglePlaygrounds/blob/master/NYC%20Taxi%20Fares%20Prediction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape torch.Size([3, 2])\n",
      "y.shape torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "x =  torch.Tensor([[1, 2, 3], [1, 2, 3]]).view(-1, 2)\n",
    "y =  torch.Tensor([[2, 1]]).view(2, -1)\n",
    "\n",
    "print('x.shape', x.shape)\n",
    "print('y.shape', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 1.],\n",
       "        [2., 3.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.],\n",
       "        [7.],\n",
       "        [7.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_device(model):\n",
    "    return str(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_torch(y_true, y_pred):\n",
    "    epsilon = 1e-7  # this epsilon value used in TF\n",
    "    SS_res = torch.sum( (y_true - y_pred)**2 )\n",
    "    SS_tot = torch.sum( (y_true - torch.mean(y_true))**2 )\n",
    "    r2 = 1 - SS_res / (SS_tot + epsilon)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Convert pandas df to torch tensors\n",
    "# xtr, ytr, xte, yte = map(torch.tensor(dtype=torch.float32), (xtr.values, ytr.values, xte.values, yte.values))\n",
    "\n",
    "def np_to_tensor(a, dtype=torch.float32):\n",
    "    return torch.tensor(a, dtype=dtype)\n",
    "\n",
    "xtr = np_to_tensor(xtr.values)\n",
    "ytr = np_to_tensor(ytr.values)\n",
    "xte = np_to_tensor(xte.values)\n",
    "yte = np_to_tensor(yte.values)\n",
    "\n",
    "print(type(xtr))\n",
    "print(xtr.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Top6DataReg(Dataset):\n",
    "    # discuss.pytorch.org/t/data-processing-as-a-batch-way/14154\n",
    "    # github.com/utkuozbulak/pytorch-custom-dataset-examples#incorporating-pandas\n",
    "    # nbviewer.jupyter.org/github/FraPochetti/KagglePlaygrounds/blob/master/NYC%20Taxi%20Fares%20Prediction.ipynb\n",
    "    \n",
    "    def __init__(self, xdata, ydata):\n",
    "        # self.x = xdata.values\n",
    "        # self.y = ydata.values\n",
    "        self.x = xdata\n",
    "        self.y = ydata\n",
    "        self.y = self.y.view(-1, 1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx, :]\n",
    "        y = self.y[idx]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_ds = Top6DataReg(xdata=xtr, ydata=ytr)\n",
    "te_ds = Top6DataReg(xdata=xte, ydata=yte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loaders\n",
    "batch_size = 32\n",
    "num_workers = 1\n",
    "tr_loader_prms = {'batch_size': batch_size, 'shuffle': True, 'num_workers': num_workers}\n",
    "te_loader_prms = {'batch_size': 4*batch_size, 'shuffle': False, 'num_workers': num_workers}\n",
    "\n",
    "tr_loader = DataLoader(tr_ds, **tr_loader_prms)\n",
    "te_loader = DataLoader(te_ds, **te_loader_prms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xb, yb = next(iter(tr_loader))\n",
    "# print(xb.shape)\n",
    "# print(yb.shape)\n",
    "# print(xb[:2])\n",
    "# print(yb[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TORCH_REGRESSOR(nn.Module):\n",
    "#     def __init__(self, input_dim):\n",
    "#         super().__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, 1000)\n",
    "#         self.fc2 = nn.Linear(1000, 1000)\n",
    "#         self.fc3 = nn.Linear(1000, 500)\n",
    "#         self.fc4 = nn.Linear(500, 250)\n",
    "#         self.fc5 = nn.Linear(250, 125)\n",
    "#         self.fc6 = nn.Linear(125, 60)\n",
    "#         self.fc7 = nn.Linear(60, 30)\n",
    "#         self.fc8 = nn.Linear(30, 1)\n",
    "#         self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.dropout(F.relu(self.fc1(x)))\n",
    "#         x = self.dropout(F.relu(self.fc2(x)))\n",
    "#         x = self.dropout(F.relu(self.fc3(x)))\n",
    "#         x = self.dropout(F.relu(self.fc4(x)))\n",
    "#         x = self.dropout(F.relu(self.fc5(x)))\n",
    "#         x = self.dropout(F.relu(self.fc6(x)))\n",
    "#         x = self.dropout(F.relu(self.fc7(x)))\n",
    "#         x = F.relu(self.fc8(x))\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TORCH_REGRESSOR(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 500)\n",
    "        self.fc3 = nn.Linear(500, 250)\n",
    "        self.fc4 = nn.Linear(250, 60)\n",
    "        self.fc5 = nn.Linear(60, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = self.dropout(F.relu(self.fc4(x)))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_available:   True\n",
      "device_name:    GeForce RTX 2080 Ti\n",
      "device_count:   4\n",
      "current_device: 0\n"
     ]
    }
   ],
   "source": [
    "# pytorch.org/docs/stable/cuda.html\n",
    "# towardsdatascience.com/speed-up-your-algorithms-part-1-pytorch-56d8a4ae7051\n",
    "print('is_available:  ', torch.cuda.is_available())\n",
    "print('device_name:   ', torch.cuda.get_device_name(0))\n",
    "print('device_count:  ', torch.cuda.device_count())\n",
    "print('current_device:', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n",
      "current_device: 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:3')\n",
    "model = TORCH_REGRESSOR(input_dim=tr_ds.x.shape[1]).to(device=device) # send model to gpu/cpu device\n",
    "print(get_model_device(model))\n",
    "print('current_device:', torch.cuda.current_device()) # why current device is 0??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "if device.type == 'cuda':\n",
    "    print(get_model_device(model))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3, 1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3, 1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "current_device: 2\n",
      "current_device: 0\n"
     ]
    }
   ],
   "source": [
    "# Choose cuda device with context manager\n",
    "with torch.cuda.device(2):\n",
    "    print('\\ncurrent_device:', torch.cuda.current_device())\n",
    "    model = TORCH_REGRESSOR(input_dim=tr_ds.x.shape[1]).to(device=device)\n",
    "print('current_device:', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fnc = nn.MSELoss(reduction='mean')\n",
    "opt = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)  # pytorch.org/docs/stable/optim.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a single training iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xb, yb = next(iter(tr_loader))\n",
    "# xb = xb.to(device)\n",
    "# yb = yb.to(device)\n",
    "# print(xb.device)\n",
    "# print(yb.device)\n",
    "\n",
    "# # Forward\n",
    "# opt.zero_grad()\n",
    "# pred = model(xb)\n",
    "\n",
    "# print(f'pred.shape {pred.shape}')\n",
    "# print(f'yb.shape {yb.shape}')\n",
    "# yb = yb.view(pred.shape)\n",
    "# print(f'yb.shape {yb.shape}\\n')\n",
    "\n",
    "# print('pred:\\n', pred[:3])\n",
    "# print('yb:\\n', yb[:3])\n",
    "# pred = pred.type(torch.float32)\n",
    "# print('pred:\\n', pred[:3])\n",
    "\n",
    "# # Backprop\n",
    "# loss = loss_fnc(pred, yb)\n",
    "# loss.backward() # compute loss gradients wrt to model parameters and inputs\n",
    "# opt.step()      # update model parameters;  pytorch.org/docs/stable/optim.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'pred.shape {pred.shape}')\n",
    "# print(f'yb.shape   {yb.shape}\\n')\n",
    "# mae = torch.abs(pred - yb)\n",
    "# r2_torch(y_true=yb, y_pred=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discuss.pytorch.org/t/what-does-torch-backends-cudnn-benchmark-do/5936\n",
    "# groups.google.com/forum/#!topic/torch7/CkB57025yRY\n",
    "# torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_batch(xb, yb, model, loss_fnc, opt=None):\n",
    "    pred = model(xb)\n",
    "    loss = loss_fnc(pred, yb)\n",
    "    \n",
    "    # Backward pass\n",
    "    if opt is not None:\n",
    "        # opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "    return loss, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(pred, yb, scores, val=False, metrics=None):\n",
    "    pred, yb = pred.numpy(), yb.numpy()\n",
    "    prfx = 'val_' if val is True else ''\n",
    "    \n",
    "    for m in metrics:\n",
    "        if m in ['mae', 'mean_absolute_error']:\n",
    "            scores[prfx + 'mean_abs_err'] = sklearn.metrics.mean_absolute_error(yb, pred)\n",
    "            \n",
    "        elif m in ['r2', 'r2_score']:\n",
    "            scores[prfx + 'r2'] = sklearn.metrics.r2_score(yb, pred)\n",
    "            \n",
    "        elif m in ['median_absolute_error']:\n",
    "            scores[prfx + 'median_abs_err'] = sklearn.metrics.median_absolute_error(yb, pred)\n",
    "            \n",
    "        elif m in ['mean_squared_error']:\n",
    "            scores[prfx + 'mean_squared_error'] = sklearn.metrics.mean_squared_error(yb, pred)\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics(scores, ph):\n",
    "    \"\"\" Similar to the history of keras. \"\"\"\n",
    "    prefix = 'val_' if ph=='val' else ''\n",
    "    logs[prefix + 'loss'] = bt_loss\n",
    "    logs[prefix + 'mae'] = bt_mae\n",
    "    logs[prefix + 'r2'] = bt_r2\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit(model: nn.Module,\n",
    "#         loss_fnc: \n",
    "#         opt: torch.optim,\n",
    "#         tr_dl: torch.utils.data.DataLoader,\n",
    "#         vl_dl: torch.utils.data.DataLoader=None,\n",
    "#         epochs: int=1,\n",
    "#         device: torch.device='cuda:0',\n",
    "#         verbose: bool=True,\n",
    "#         metrics=None) -> dict:\n",
    "#     # github.com/stared/livelossplot/blob/master/examples/pytorch.ipynb\n",
    "    \n",
    "#     print(f'device: {device}')\n",
    "#     model.to(device)  \n",
    "#     logs = OrderedDict()\n",
    "    \n",
    "#     for ep in range(epochs):\n",
    "#         ep_t0 = time()\n",
    "        \n",
    "#         model.train()\n",
    "#         bt_loss, bt_mae, bt_r2 = 0, 0, 0\n",
    "#         for xb, yb in tr_dl:\n",
    "#             xb = xb.to(device)\n",
    "#             yb = yb.to(device)\n",
    "#             loss, pred = proc_batch(xb, yb, model, loss_fnc, opt=opt)\n",
    "#             # logs = calc_metrics(yb, pred, logs, phase=False, metrics=metrics)\n",
    "#             # logs = pd.DataFrame(logs)\n",
    "            \n",
    "#             pred, yb = pred.numpy(), yb.numpy()\n",
    "#             bt_mae += sklearn.metrics.mean_absolute_error(yb, pred)\n",
    "#             bt_r2 += sklearn.metrics.r2_score(yb, pred)\n",
    "            \n",
    "#         # logs = logs.sum(axis=0)/len(dl)\n",
    "        \n",
    "#         bt_loss /= len(dl)\n",
    "#         bt_mae /= len(dl)\n",
    "#         bt_r2 /= len(dl)\n",
    "\n",
    "#         # Log metrics\n",
    "#         prefix = ''\n",
    "#         logs[prefix + 'loss'] = bt_loss\n",
    "#         logs[prefix + 'mae'] = bt_mae\n",
    "#         logs[prefix + 'r2'] = bt_r2        \n",
    "        \n",
    "#         if vl_dl is not None:\n",
    "#             model.eval()\n",
    "#             bt_loss, bt_mae, bt_r2 = 0, 0, 0\n",
    "#             with torch.no_grad():\n",
    "#                 for xb, yb in vl_dl:\n",
    "#                     xb = xb.to(device)\n",
    "#                     yb = yb.to(device)\n",
    "#                     loss, pred = proc_batch(xb, yb, model, loss_fnc, opt=None)\n",
    "#                     # logs = calc_metrics(yb, pred, logs, val=True, metrics=metrics)\n",
    "                \n",
    "#                     pred, yb = pred.numpy(), yb.numpy()\n",
    "#                     bt_mae += sklearn.metrics.mean_absolute_error(yb, pred)\n",
    "#                     bt_r2 += sklearn.metrics.r2_score(yb, pred)\n",
    "  \n",
    "#                 bt_loss /= len(dl)\n",
    "#                 bt_mae /= len(dl)\n",
    "#                 bt_r2 /= len(dl) \n",
    "\n",
    "#                 # Log metrics\n",
    "#                 prefix = 'val_'\n",
    "#                 logs[prefix + 'loss'] = bt_loss\n",
    "#                 logs[prefix + 'mae'] = bt_mae\n",
    "#                 logs[prefix + 'r2'] = bt_r2            \n",
    "        \n",
    "#         if verbose:\n",
    "#             print(f'Epoch {ep+1}/{epochs}; ',\n",
    "#                   f'{int(time()-ep_t0)}s; ',\n",
    "#                   [f'{k}: {v:.3f}' for k, v in logs.items()])\n",
    "        \n",
    "#     return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Using phases = ['train', 'val']\n",
    "# -------------------------------\n",
    "def fit(model: nn.Module,\n",
    "        loss_fnc, \n",
    "        opt: torch.optim,\n",
    "        tr_dl: torch.utils.data.DataLoader,\n",
    "        vl_dl: torch.utils.data.DataLoader=None,\n",
    "        epochs: int=1,\n",
    "        device: torch.device='cuda:0',\n",
    "        verbose: bool=True,\n",
    "        metrics=None) -> dict:\n",
    "    \"\"\" ... \"\"\"\n",
    "    print(f'\\ndevice: {device}')\n",
    "    model.to(device)  \n",
    "    \n",
    "    with torch.cuda.device(device):\n",
    "        print('current_device:', torch.cuda.current_device())    \n",
    "    \n",
    "        # Similar to keras `history`\n",
    "        logs = OrderedDict()\n",
    "\n",
    "        for ep in range(epochs):\n",
    "            ep_t0 = time()\n",
    "            phases = ['train', 'val'] if vl_dl is not None else ['train']\n",
    "\n",
    "            for ph in phases:\n",
    "                if ph == 'train':\n",
    "                    model.train()\n",
    "                    dl = tr_dl\n",
    "                elif ph == 'val':\n",
    "                    model.eval()\n",
    "                    dl = vl_dl\n",
    "\n",
    "                bt_loss = 0\n",
    "                bt_mae = 0\n",
    "                bt_r2 = 0\n",
    "\n",
    "                for xb, yb in dl:\n",
    "                    xb = xb.to(device)\n",
    "                    yb = yb.to(device)\n",
    "\n",
    "                    # Zero parameter gradients\n",
    "                    opt.zero_grad()\n",
    "\n",
    "                    with torch.set_grad_enabled(ph=='train'):\n",
    "                        input_opt = opt if ph=='train' else None\n",
    "                        loss, pred = proc_batch(xb, yb, model, loss_fnc, opt=input_opt)\n",
    "\n",
    "                        # Compute metrics\n",
    "                        # logs = calc_metrics(yb, pred, logs, phase=False, metrics=metrics)\n",
    "                        bt_loss += loss.item() # item() returns a number from a tensor that contains a single value\n",
    "                        bt_mae += torch.mean(torch.abs(pred-yb)).item()\n",
    "                        bt_r2 += r2_torch(y_true=yb, y_pred=pred).item()\n",
    "\n",
    "                        # Gives error: RuntimeError: Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead.\n",
    "                        # pred, yb = pred.numpy(), yb.numpy()\n",
    "                        # bt_mae += np.mean(np.abs(pred-yb))\n",
    "                        # bt_r2 += r2_score(y_true=yb, y_pred=pred)\n",
    "\n",
    "                bt_loss /= len(dl)\n",
    "                bt_mae /= len(dl)\n",
    "                bt_r2 /= len(dl)          \n",
    "\n",
    "                # Log metrics\n",
    "                # logs = log_metrics(scores, ph)\n",
    "                prefix = 'val_' if ph=='val' else ''\n",
    "                logs[prefix + 'loss'] = bt_loss\n",
    "                logs[prefix + 'mae'] = bt_mae\n",
    "                logs[prefix + 'r2'] = bt_r2\n",
    "\n",
    "            if verbose:\n",
    "#                 print(f'Epoch {ep+1}/{epochs}; ',\n",
    "#                       f'{int(time()-ep_t0)}s; ',\n",
    "#                       [f'{k}: {v:.3f}' for k, v in logs.items()])\n",
    "                l = [f'{k}: {v:.3f}' for k, v in logs.items()]\n",
    "                print(f'Epoch {ep+1}/{epochs}; ',\n",
    "                      f'{int(time()-ep_t0)}s; ',\n",
    "                      *l)                \n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "current_device: 2\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'te_loss_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-62ba2336b103>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mte_r2\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mte_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mte_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mte_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mte_mae_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mte_mae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mte_r2_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mte_r2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'te_loss_list' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "tr_loss_list = []\n",
    "tr_mae_list = []\n",
    "tr_r2_list = []\n",
    "\n",
    "te_loss_list = []\n",
    "te_mae_list = []\n",
    "te_r2_list = []\n",
    "\n",
    "# logs = OrderedDict()\n",
    "\n",
    "# Choose cuda device with context manager\n",
    "with torch.cuda.device(device):\n",
    "    print('\\ncurrent_device:', torch.cuda.current_device())\n",
    "    \n",
    "    for ep in range(epochs):\n",
    "        t0 = time()\n",
    "\n",
    "        # Training loop\n",
    "        model.train() # turns-on dropout for training\n",
    "        tr_loss, tr_mae, tr_r2 = 0, 0, 0\n",
    "\n",
    "        for xb, yb in tr_loader:\n",
    "            xb = xb.to(device) # move data to gpu/cpu device\n",
    "            yb = yb.to(device) # move data to gpu/cpu device\n",
    "            \n",
    "            # Feedforward\n",
    "            pred = model(xb)\n",
    "            loss = loss_fnc(pred, yb)\n",
    "\n",
    "            # Backprop and optimization\n",
    "            opt.zero_grad()\n",
    "            loss.backward()   # compute loss gradients wrt to model parameters and inputs\n",
    "            opt.step()  # update model parameters;  pytorch.org/docs/stable/optim.html\n",
    "            \n",
    "            # Compute metrics\n",
    "            tr_loss += loss.item() # item() returns a number from a tensor that contains a single value\n",
    "            tr_mae += torch.mean(torch.abs(pred-yb))\n",
    "            tr_r2 += r2_torch(y_true=yb, y_pred=pred)\n",
    "\n",
    "        tr_loss /= len(tr_loader)\n",
    "        tr_mae /= len(tr_loader)\n",
    "        tr_r2 /= len(tr_loader)\n",
    "\n",
    "        tr_loss_list.append(tr_loss)\n",
    "        tr_mae_list.append(tr_mae)\n",
    "        tr_r2_list.append(tr_r2)\n",
    "\n",
    "        del xb, yb\n",
    "\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()  # turn-off dropout in inferenece\n",
    "        with torch.no_grad():\n",
    "            te_loss, te_mae, te_r2 = 0, 0, 0\n",
    "\n",
    "            for xb, yb in te_loader:\n",
    "                xb = xb.to(device)\n",
    "                yb = yb.to(device)\n",
    "            \n",
    "                # Feedforward\n",
    "                pred = model(xb)\n",
    "                loss = loss_fnc(pred, yb)\n",
    "\n",
    "                # Compute metrics\n",
    "                te_loss += loss.item() # item() returns a number from a tensor that contains a single value\n",
    "                te_mae += torch.mean(torch.abs(pred-yb))\n",
    "                te_r2 += r2_torch(y_true=yb, y_pred=pred)\n",
    "\n",
    "            te_loss /= len(te_loader)\n",
    "            te_mae /= len(te_loader)\n",
    "            te_r2 /= len(te_loader)\n",
    "\n",
    "        te_loss_list.append(te_loss)\n",
    "        te_mae_list.append(te_mae)\n",
    "        te_r2_list.append(te_r2)\n",
    "\n",
    "        del xb, yb\n",
    "\n",
    "        print(f'Epoch {ep+1}/{epochs}; ',\n",
    "              f'{int(time()-t0)}s; '\n",
    "              f'tr_loss: {tr_loss:.3f}; ',\n",
    "              f'vl_loss: {te_loss:.3f}; ',\n",
    "              f'tr_mae: {tr_mae:.3f}; ',\n",
    "              f'vl_mae: {te_mae:.3f}; ',\n",
    "              f'tr_r2: {tr_r2:.3f}; ',\n",
    "              f'vl_r2: {te_r2:.3f}; ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Epoch {ep}/{epochs}; ',\n",
    "#       f'{int(time()-t0):>10}s; ',\n",
    "#       f'tr_loss: {tr_loss:.4f}; ',\n",
    "#       f'vl_loss: {te_loss:.4f}; ',\n",
    "#       f'tr_mae: {tr_mae:.4f}; ',\n",
    "#       f'vl_mae: {te_mae:.4f}; ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tr_mae_vec);\n",
    "plt.plot(te_mae_vec);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03142730247974396"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 hello 0 1 2 3 4\n"
     ]
    }
   ],
   "source": [
    "a = 1\n",
    "b = 'hello'\n",
    "l = [x for x in range(5)]\n",
    "# print(f'{a}; {b}; {*[x for x in range(5)]}')\n",
    "# print(f'{a}; {b}; {' '.join(l)}')\n",
    "print(a, b, *l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
