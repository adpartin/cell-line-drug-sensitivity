{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top6 from Rick\n",
    "# datadir = Path('../data/processed/topN/topNrick/')\n",
    "# datapath = datadir/'uniq.top6.reg.parquet'\n",
    "\n",
    "# Top6 from code\n",
    "datadir = Path('../data/processed/topN/topNcode/')\n",
    "datapath = datadir/'top_6.res_reg.cf_rnaseq.dd_dragon7.labled.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create mini Top6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_parquet(datapath, engine='auto', columns=None)\n",
    "# data = data.sample(frac=1.0, axis=0, random_state=SEED).reset_index(drop=True)\n",
    "# print(data.shape)\n",
    "\n",
    "# col_idx = data.nunique(dropna=True).values == 1  # col indexes to drop\n",
    "# data = data.iloc[:, ~col_idx]\n",
    "# print(data.shape)\n",
    "\n",
    "# def subset(data, s):\n",
    "#     if s <= 1.0:\n",
    "#         data_size = int(data.shape[0]*s)\n",
    "#     return data[:data_size]\n",
    "\n",
    "# data = subset(data, s=0.3)\n",
    "# print(data.shape)\n",
    "# # data.to_csv(datadir/'uniq.top6.reg.mini.csv', index=False)\n",
    "# data.to_parquet(datadir/'uniq.top6.reg.mini.parquet', index=False)\n",
    "\n",
    "# display(data[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85501, 3763)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "# data = pd.read_csv(datadir/'uniq.top6.reg.mini.csv')\n",
    "data = pd.read_parquet(datadir/'uniq.top6.reg.mini.parquet')\n",
    "print(data.shape)\n",
    "\n",
    "if 'topNcode' in str(datadir):\n",
    "    data.drop(columns=['CELL', 'DRUG'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68400, 3761)\n",
      "(17101, 3761)\n"
     ]
    }
   ],
   "source": [
    "# Split train/test\n",
    "df_tr, df_te = train_test_split(data, test_size=0.2)\n",
    "df_tr = df_tr.reset_index(drop=True)\n",
    "df_te = df_te.reset_index(drop=True)\n",
    "print(df_tr.shape)\n",
    "print(df_te.shape)\n",
    "\n",
    "# Split features/target\n",
    "ytr, xtr = df_tr.iloc[:,0], df_tr.iloc[:,1:]\n",
    "yte, xte = df_te.iloc[:,0], df_te.iloc[:,1:]\n",
    "\n",
    "del data, df_tr, df_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68400, 3760)\n",
      "(17101, 3760)\n",
      "(68400,)\n",
      "(17101,)\n"
     ]
    }
   ],
   "source": [
    "# Scale\n",
    "col_names = xtr.columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "xtr = pd.DataFrame( scaler.fit_transform(xtr) ).astype(np.float32)\n",
    "xte = pd.DataFrame( scaler.transform(xte) ).astype(np.float32)\n",
    "\n",
    "xtr.columns = col_names\n",
    "xte.columns = col_names\n",
    "\n",
    "print(xtr.shape)\n",
    "print(xte.shape)\n",
    "print(ytr.shape)\n",
    "print(yte.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "https://nbviewer.jupyter.org/github/FraPochetti/KagglePlaygrounds/blob/master/NYC%20Taxi%20Fares%20Prediction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape torch.Size([3, 2])\n",
      "y.shape torch.Size([2, 1])\n",
      "\n",
      "x\n",
      " tensor([[1., 2.],\n",
      "        [3., 1.],\n",
      "        [2., 3.]])\n",
      "\n",
      "y\n",
      " tensor([[2.],\n",
      "        [1.]])\n",
      "\n",
      "x * y\n",
      " tensor([[4.],\n",
      "        [7.],\n",
      "        [7.]])\n"
     ]
    }
   ],
   "source": [
    "x =  torch.Tensor([[1, 2, 3], [1, 2, 3]]).view(-1, 2)\n",
    "y =  torch.Tensor([[2, 1]]).view(2, -1)\n",
    "\n",
    "print('x.shape', x.shape)\n",
    "print('y.shape', y.shape)\n",
    "\n",
    "print('\\nx\\n', x)\n",
    "print('\\ny\\n', y)\n",
    "print('\\nx * y\\n', torch.mm(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert pandas df to torch tensors\n",
    "# def np_to_tensor(a, dtype=torch.float32):\n",
    "#     \"\"\" Convert np arr to tensor. \"\"\"\n",
    "#     return torch.tensor(a, dtype=dtype)\n",
    "\n",
    "# # xtr, ytr, xte, yte = map(np_to_tensor, (xtr.values, ytr.values, xte.values, yte.values))\n",
    "\n",
    "# xtr = np_to_tensor(xtr.values, dtype=torch.float32)\n",
    "# ytr = np_to_tensor(ytr.values, dtype=torch.float32)\n",
    "# xte = np_to_tensor(xte.values, dtype=torch.float32)\n",
    "# yte = np_to_tensor(yte.values, dtype=torch.float32)\n",
    "\n",
    "# print(type(xtr))\n",
    "# print(xtr.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Top6Dataset(Dataset):\n",
    "    # discuss.pytorch.org/t/data-processing-as-a-batch-way/14154\n",
    "    # github.com/utkuozbulak/pytorch-custom-dataset-examples#incorporating-pandas\n",
    "    # nbviewer.jupyter.org/github/FraPochetti/KagglePlaygrounds/blob/master/NYC%20Taxi%20Fares%20Prediction.ipynb\n",
    "    def __init__(self,\n",
    "                 xdata: pd.DataFrame,\n",
    "                 ydata: pd.DataFrame):\n",
    "        # xdata and ydata are pandas dfs\n",
    "        xdata = pd.DataFrame(xdata).values\n",
    "        ydata = pd.DataFrame(ydata).values\n",
    "        self.x = torch.tensor(xdata, dtype=torch.float32)\n",
    "        self.y = torch.tensor(ydata, dtype=torch.float32)\n",
    "        self.y = self.y.view(-1, 1)\n",
    "        \n",
    "        # xdata and ydata are torch tensors\n",
    "        #self.x = xdata\n",
    "        #self.y = ydata\n",
    "        #self.y = self.y.view(-1, 1)        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx, :]\n",
    "        y = self.y[idx]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_ds = Top6Dataset(xdata=xtr, ydata=ytr)\n",
    "vl_ds = Top6Dataset(xdata=xte, ydata=yte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loaders\n",
    "batch_size = 32\n",
    "num_workers = 1\n",
    "tr_loader_kwargs = {'batch_size': batch_size, 'shuffle': True, 'num_workers': num_workers}\n",
    "vl_loader_kwargs = {'batch_size': 4*batch_size, 'shuffle': False, 'num_workers': num_workers}\n",
    "\n",
    "tr_loader = DataLoader(tr_ds, **tr_loader_kwargs)\n",
    "vl_loader = DataLoader(vl_ds, **vl_loader_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xb, yb = next(iter(tr_loader))\n",
    "# print(xb.shape)\n",
    "# print(yb.shape)\n",
    "# print(xb[:2])\n",
    "# print(yb[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_REG(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 500)\n",
    "        self.fc4 = nn.Linear(500, 250)\n",
    "        self.fc5 = nn.Linear(250, 125)\n",
    "        self.fc6 = nn.Linear(125, 60)\n",
    "        self.fc7 = nn.Linear(60, 30)\n",
    "        self.fc8 = nn.Linear(30, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = self.dropout(F.relu(self.fc4(x)))\n",
    "        x = self.dropout(F.relu(self.fc5(x)))\n",
    "        x = self.dropout(F.relu(self.fc6(x)))\n",
    "        x = self.dropout(F.relu(self.fc7(x)))\n",
    "        x = F.relu(self.fc8(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_REG(nn.Module):\n",
    "    def __init__(self, input_dim, dr_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 500)\n",
    "        self.fc3 = nn.Linear(500, 250)\n",
    "        self.fc4 = nn.Linear(250, 60)\n",
    "        self.fc5 = nn.Linear(60, 1)\n",
    "        self.dropout = nn.Dropout(dr_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = self.dropout(F.relu(self.fc4(x)))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init_linear(m: nn.Module):\n",
    "    # Weight initialization\n",
    "    \"\"\"\n",
    "    Pytorch initializes the layers by default (e.g., Linear uses kaiming_uniform_)\n",
    "    www.deeplearningwizard.com/deep_learning/boosting_models_pytorch/weight_initialization_activation_functions/\n",
    "    stackoverflow.com/questions/49433936/how-to-initialize-weights-in-pytorch\n",
    "    github.com/xduan7/UnoPytorch/blob/master/networks/initialization/weight_init.py\n",
    "    \"\"\"\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model to CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_device(model):\n",
    "    return str(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_available:   True\n",
      "device_name:    GeForce RTX 2080 Ti\n",
      "device_count:   4\n",
      "current_device: 0\n"
     ]
    }
   ],
   "source": [
    "# pytorch.org/docs/stable/cuda.html\n",
    "# towardsdatascience.com/speed-up-your-algorithms-part-1-pytorch-56d8a4ae7051\n",
    "print('is_available:  ', torch.cuda.is_available())\n",
    "print('device_name:   ', torch.cuda.get_device_name(0))\n",
    "print('device_count:  ', torch.cuda.device_count())\n",
    "print('current_device:', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n",
      "current_device: 0\n"
     ]
    }
   ],
   "source": [
    "# Choose device\n",
    "device = torch.device('cuda:3')\n",
    "\n",
    "# Move model to CUDA device\n",
    "model = NN_REG(input_dim=tr_ds.x.shape[1]).to(device) # send model to gpu/cpu device\n",
    "model.apply(weight_init_linear)\n",
    "\n",
    "# Query device where the model is located\n",
    "print(get_model_device(model))\n",
    "print('current_device:', torch.cuda.current_device()) # why current device is 0??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if device.type == 'cuda':\n",
    "#     print(get_model_device(model))\n",
    "#     print('Memory Usage:')\n",
    "#     print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3, 1), 'GB')\n",
    "#     print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3, 1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Choose cuda device with context manager\n",
    "# with torch.cuda.device(2):\n",
    "#     print('\\ncurrent_device:', torch.cuda.current_device())\n",
    "#     model = NN_REG(input_dim=tr_ds.x.shape[1]).to(device=device)\n",
    "# print('current_device:', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fnc = nn.MSELoss(reduction='mean')\n",
    "opt = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)  # pytorch.org/docs/stable/optim.html\n",
    "# lr_scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer=opt, base_lr=1e-5, max_lr=1e-3, mode='triangular')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a single training iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n",
      "cuda:3\n",
      "pred.shape torch.Size([32, 1])\n",
      "yb.shape torch.Size([32, 1])\n",
      "yb.shape torch.Size([32, 1])\n",
      "\n",
      "pred:\n",
      " tensor([[0.4251],\n",
      "        [0.4424],\n",
      "        [0.0000]], device='cuda:3', grad_fn=<SliceBackward>)\n",
      "yy:\n",
      " tensor([[1.0000],\n",
      "        [0.9567],\n",
      "        [0.9802]], device='cuda:3')\n",
      "pred:\n",
      " tensor([[0.4251],\n",
      "        [0.4424],\n",
      "        [0.0000]], device='cuda:3', grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "xx, yy = next(iter(tr_loader))\n",
    "xx = xx.to(device)\n",
    "yy = yy.to(device)\n",
    "print(xx.device)\n",
    "print(yy.device)\n",
    "\n",
    "# Forward\n",
    "opt.zero_grad()\n",
    "pred = model(xx)\n",
    "\n",
    "print(f'pred.shape {pred.shape}')\n",
    "print(f'yb.shape {yy.shape}')\n",
    "yy = yy.view(pred.shape)\n",
    "print(f'yb.shape {yy.shape}\\n')\n",
    "\n",
    "print('pred:\\n', pred[:3])\n",
    "print('yy:\\n', yy[:3])\n",
    "pred = pred.type(torch.float32)\n",
    "print('pred:\\n', pred[:3])\n",
    "\n",
    "# Backprop\n",
    "loss = loss_fnc(pred, yy)\n",
    "loss.backward() # compute loss gradients wrt to model parameters and inputs\n",
    "opt.step()      # update model parameters;  pytorch.org/docs/stable/optim.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'pred.shape {pred.shape}')\n",
    "# print(f'yb.shape   {yb.shape}\\n')\n",
    "# mae = torch.abs(pred - yb)\n",
    "# r2_torch(y_true=yb, y_pred=pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discuss.pytorch.org/t/what-does-torch-backends-cudnn-benchmark-do/5936\n",
    "# groups.google.com/forum/#!topic/torch7/CkB57025yRY\n",
    "# torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_torch(y_true, y_pred):\n",
    "    epsilon = 1e-7  # this epsilon value used in TF\n",
    "    SS_res = torch.sum( (y_true - y_pred)**2 )\n",
    "    SS_tot = torch.sum( (y_true - torch.mean(y_true))**2 )\n",
    "    r2 = 1 - SS_res / (SS_tot + epsilon)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_reg_scores(pred, true, metrics, val=False):\n",
    "#     prfx = 'val_' if val is True else '' \n",
    "#     scores = {}\n",
    "    \n",
    "#     for m in metrics:\n",
    "#         if 'loss' in m:\n",
    "#             continue\n",
    "            \n",
    "#         elif m in ['mean_abs_err', 'mean_absolute_error']:\n",
    "#             scores[prfx + 'mean_abs_err'] = torch.mean(torch.abs(pred-true))\n",
    "\n",
    "#         elif m in ['median_abs_err', 'median_absolute_error']:\n",
    "#             scores[prfx + 'median_abs_err'] = torch.median(torch.abs(pred-true))\n",
    "\n",
    "#         elif m in ['mean_sqrd_err', 'mean_squared_error']:\n",
    "#             scores[prfx + 'mean_sqrd_err'] = torch.mean(torch.pow(pred-true, 0.5))  # or torch.mean(torch.sqrt(pred-true))\n",
    "            \n",
    "#         elif m in ['r2', 'r2_score']:\n",
    "#             scores[prfx + 'r2'] = r2_torch(y_true=true, y_pred=pred)\n",
    "            \n",
    "#     return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_scores_reg(pred, true, scores):\n",
    "    \"\"\" Updates score metrics for regression ML predictions.\n",
    "    The scores are summed for every call of the function (single func call corresponds a single batch).\n",
    "    \n",
    "    Note: these must be implemented with pytroch commands! Otherwise, results gives error:\n",
    "    RuntimeError: Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead.   \n",
    "    pred, true = pred.numpy(), yy.numpy()\n",
    "    tr_mae += sklearn.metrics.mean_absolute_error(true, pred)\n",
    "    tr_r2 += sklearn.metrics.r2_score(true, pred)\n",
    "    \"\"\"\n",
    "    for m in scores.keys():\n",
    "        if 'loss' in m:\n",
    "            continue\n",
    "            \n",
    "        elif any([True if v in m else False for v in ['mean_abs_err', 'mean_absolute_error']]):\n",
    "            scores[m] += torch.mean( torch.abs(pred-true) ).item()\n",
    "\n",
    "        elif any([True if v in m else False for v in ['median_abs_err', 'median_absolute_error']]):\n",
    "            scores[m] += torch.median( torch.abs(pred-true) ).item()\n",
    "\n",
    "        elif any([True if v in m else False for v in ['mean_sqrd_err', 'mean_squared_error']]):\n",
    "            scores[m] += torch.mean( torch.pow(pred-true, 0.5) ).item()  # or torch.mean(torch.sqrt(pred-true))\n",
    "            \n",
    "        elif any([True if v in m else False for v in ['r2', 'r2_score']]):\n",
    "            scores[m] += r2_torch(y_true=true, y_pred=pred).item()\n",
    "            \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def proc_batch(xx, yy, model, loss_fnc, opt=None):\n",
    "def proc_batch(xx_dct, yy, model, loss_fnc, opt=None):\n",
    "    \"\"\" \n",
    "    Args:\n",
    "        opt (torch.optim) : no backprop is performed if optimizer is not provided (for val or test) \n",
    "    \"\"\"\n",
    "    # pred = model(xx)\n",
    "    # loss = loss_fnc(pred, yy)\n",
    "    \n",
    "    pred = model(**xx_dct)\n",
    "    pred = pred.type(yy.dtype)\n",
    "    loss = loss_fnc(pred, yy)\n",
    "    \n",
    "    # Backward pass\n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "    return loss, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model: nn.Module,\n",
    "        loss_fnc,\n",
    "        opt: torch.optim,\n",
    "        tr_dl: torch.utils.data.DataLoader,\n",
    "        vl_dl: torch.utils.data.DataLoader=None,\n",
    "        epochs: int=1,\n",
    "        device: torch.device='cuda:0',\n",
    "        verbose: bool=True,\n",
    "        metrics=[]) -> dict:\n",
    "    \"\"\" github.com/stared/livelossplot/blob/master/examples/pytorch.ipynb\n",
    "    Args:\n",
    "        metrics (list) : list of metric scores to log\n",
    "            (available metrics: 'mean_abs_err','median_abs_err', 'mean_sqrd_err', 'r2)\n",
    "    \"\"\" \n",
    "    print(f'Arg `device`: {device}')\n",
    "    model.to(device)\n",
    "    print('current_device:', torch.cuda.current_device())\n",
    "    \n",
    "    # Choose cuda device with context manager --> try using context manager!!!\n",
    "    # with torch.cuda.device(device):\n",
    "        \n",
    "    # Create dicts to log scores\n",
    "    if vl_dl is None:\n",
    "        logs = OrderedDict({'loss': []})\n",
    "        logs.update(OrderedDict({m: [] for m in metrics}))        \n",
    "    else:\n",
    "        logs = OrderedDict({'loss': [], 'val_loss': []})\n",
    "        for m in metrics: logs.update(OrderedDict({m: [], 'val_'+m: []}))\n",
    "    \n",
    "    # Iter over epochs\n",
    "    phases = ['train', 'val'] if vl_dl is not None else ['train']\n",
    "    for ep in range(epochs):\n",
    "        ep_t0 = time()\n",
    "        # lr_scheduler.step()\n",
    "        \n",
    "        for ph in phases:\n",
    "            if ph == 'train':\n",
    "                model.train()\n",
    "                dl = tr_dl\n",
    "                scores = {m: 0 for m in logs.keys() if 'val' not in m}\n",
    "                loss_name = 'loss'\n",
    "            elif ph == 'val':\n",
    "                model.eval()\n",
    "                dl = vl_dl\n",
    "                scores = {m: 0 for m in logs.keys() if 'val' in m}\n",
    "                loss_name = 'val_loss'\n",
    "\n",
    "            # Iter over batches\n",
    "            for xx, yy in dl:\n",
    "                yy = yy.to(device)\n",
    "                xx = xx.to(device)\n",
    "                xx_dct = {'x': xx} # new\n",
    "                \n",
    "                # Process batch\n",
    "                if ph == 'train':\n",
    "                    # loss, pred = proc_batch(xx, yy, model=model, loss_fnc=loss_fnc, opt=opt) # new\n",
    "                    loss, pred = proc_batch(xx_dct, yy, model=model, loss_fnc=loss_fnc, opt=opt) # new\n",
    "                else:\n",
    "                    # loss, pred = proc_batch(xx, yy, model=model, loss_fnc=loss_fnc, opt=None) # new\n",
    "                    loss, pred = proc_batch(xx_dct, yy, model=model, loss_fnc=loss_fnc, opt=None) # new\n",
    "\n",
    "                # Compute metrics (running avg)\n",
    "                scores[loss_name] += loss.item()\n",
    "                scores = update_scores_reg(pred=pred, true=yy, scores=scores)\n",
    "            \n",
    "            # Log scores\n",
    "            for m in scores.keys():\n",
    "                logs[m].append(scores[m]/len(dl))\n",
    "            \n",
    "        del xx, yy, loss, pred, scores\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'Epoch {ep+1}/{epochs}; ',\n",
    "                  f'{int(time()-ep_t0)}s; ',\n",
    "                  [f'{k}: {v[-1]:.3f}' for k, v in logs.items()])\n",
    "            \n",
    "        # TODO: log scores into file\n",
    "\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arg `device`: cuda:3\n",
      "current_device: 0\n",
      "Epoch 1/30;  7s;  ['loss: 0.015', 'val_loss: 0.014', 'mean_abs_err: 0.093', 'val_mean_abs_err: 0.092', 'r2: 0.259', 'val_r2: 0.355']\n",
      "Epoch 2/30;  8s;  ['loss: 0.015', 'val_loss: 0.014', 'mean_abs_err: 0.093', 'val_mean_abs_err: 0.091', 'r2: 0.258', 'val_r2: 0.361']\n",
      "Epoch 3/30;  7s;  ['loss: 0.015', 'val_loss: 0.014', 'mean_abs_err: 0.092', 'val_mean_abs_err: 0.090', 'r2: 0.263', 'val_r2: 0.365']\n",
      "Epoch 4/30;  8s;  ['loss: 0.015', 'val_loss: 0.014', 'mean_abs_err: 0.092', 'val_mean_abs_err: 0.091', 'r2: 0.269', 'val_r2: 0.364']\n",
      "Epoch 5/30;  8s;  ['loss: 0.015', 'val_loss: 0.014', 'mean_abs_err: 0.092', 'val_mean_abs_err: 0.088', 'r2: 0.267', 'val_r2: 0.376']\n",
      "Epoch 6/30;  7s;  ['loss: 0.015', 'val_loss: 0.014', 'mean_abs_err: 0.092', 'val_mean_abs_err: 0.089', 'r2: 0.270', 'val_r2: 0.374']\n",
      "Epoch 7/30;  7s;  ['loss: 0.015', 'val_loss: 0.014', 'mean_abs_err: 0.092', 'val_mean_abs_err: 0.090', 'r2: 0.272', 'val_r2: 0.369']\n",
      "Epoch 8/30;  7s;  ['loss: 0.015', 'val_loss: 0.014', 'mean_abs_err: 0.092', 'val_mean_abs_err: 0.090', 'r2: 0.277', 'val_r2: 0.372']\n",
      "Epoch 9/30;  8s;  ['loss: 0.015', 'val_loss: 0.014', 'mean_abs_err: 0.091', 'val_mean_abs_err: 0.089', 'r2: 0.280', 'val_r2: 0.377']\n",
      "Epoch 10/30;  7s;  ['loss: 0.015', 'val_loss: 0.013', 'mean_abs_err: 0.091', 'val_mean_abs_err: 0.088', 'r2: 0.281', 'val_r2: 0.383']\n",
      "Epoch 11/30;  8s;  ['loss: 0.015', 'val_loss: 0.013', 'mean_abs_err: 0.091', 'val_mean_abs_err: 0.088', 'r2: 0.283', 'val_r2: 0.384']\n",
      "Epoch 12/30;  8s;  ['loss: 0.015', 'val_loss: 0.013', 'mean_abs_err: 0.091', 'val_mean_abs_err: 0.089', 'r2: 0.283', 'val_r2: 0.382']\n",
      "Epoch 13/30;  8s;  ['loss: 0.015', 'val_loss: 0.013', 'mean_abs_err: 0.091', 'val_mean_abs_err: 0.088', 'r2: 0.285', 'val_r2: 0.387']\n",
      "Epoch 14/30;  8s;  ['loss: 0.015', 'val_loss: 0.013', 'mean_abs_err: 0.091', 'val_mean_abs_err: 0.088', 'r2: 0.283', 'val_r2: 0.384']\n",
      "Epoch 15/30;  8s;  ['loss: 0.015', 'val_loss: 0.013', 'mean_abs_err: 0.090', 'val_mean_abs_err: 0.089', 'r2: 0.293', 'val_r2: 0.383']\n",
      "Epoch 16/30;  8s;  ['loss: 0.015', 'val_loss: 0.013', 'mean_abs_err: 0.090', 'val_mean_abs_err: 0.087', 'r2: 0.287', 'val_r2: 0.390']\n",
      "Epoch 17/30;  7s;  ['loss: 0.015', 'val_loss: 0.013', 'mean_abs_err: 0.090', 'val_mean_abs_err: 0.087', 'r2: 0.292', 'val_r2: 0.393']\n",
      "Epoch 18/30;  7s;  ['loss: 0.014', 'val_loss: 0.013', 'mean_abs_err: 0.090', 'val_mean_abs_err: 0.087', 'r2: 0.291', 'val_r2: 0.392']\n",
      "Epoch 19/30;  8s;  ['loss: 0.014', 'val_loss: 0.013', 'mean_abs_err: 0.090', 'val_mean_abs_err: 0.088', 'r2: 0.298', 'val_r2: 0.392']\n",
      "Epoch 20/30;  8s;  ['loss: 0.014', 'val_loss: 0.013', 'mean_abs_err: 0.090', 'val_mean_abs_err: 0.087', 'r2: 0.300', 'val_r2: 0.395']\n",
      "Epoch 21/30;  8s;  ['loss: 0.014', 'val_loss: 0.013', 'mean_abs_err: 0.090', 'val_mean_abs_err: 0.087', 'r2: 0.301', 'val_r2: 0.395']\n",
      "Epoch 22/30;  8s;  ['loss: 0.014', 'val_loss: 0.013', 'mean_abs_err: 0.089', 'val_mean_abs_err: 0.087', 'r2: 0.304', 'val_r2: 0.397']\n",
      "Epoch 23/30;  8s;  ['loss: 0.014', 'val_loss: 0.013', 'mean_abs_err: 0.089', 'val_mean_abs_err: 0.086', 'r2: 0.306', 'val_r2: 0.401']\n",
      "Epoch 24/30;  7s;  ['loss: 0.014', 'val_loss: 0.013', 'mean_abs_err: 0.089', 'val_mean_abs_err: 0.088', 'r2: 0.307', 'val_r2: 0.395']\n",
      "Epoch 25/30;  7s;  ['loss: 0.014', 'val_loss: 0.013', 'mean_abs_err: 0.089', 'val_mean_abs_err: 0.086', 'r2: 0.307', 'val_r2: 0.403']\n",
      "Epoch 26/30;  8s;  ['loss: 0.014', 'val_loss: 0.013', 'mean_abs_err: 0.089', 'val_mean_abs_err: 0.086', 'r2: 0.308', 'val_r2: 0.404']\n",
      "Epoch 27/30;  7s;  ['loss: 0.014', 'val_loss: 0.013', 'mean_abs_err: 0.089', 'val_mean_abs_err: 0.086', 'r2: 0.309', 'val_r2: 0.405']\n",
      "Epoch 28/30;  8s;  ['loss: 0.014', 'val_loss: 0.013', 'mean_abs_err: 0.089', 'val_mean_abs_err: 0.086', 'r2: 0.312', 'val_r2: 0.407']\n",
      "Epoch 29/30;  7s;  ['loss: 0.014', 'val_loss: 0.013', 'mean_abs_err: 0.089', 'val_mean_abs_err: 0.086', 'r2: 0.312', 'val_r2: 0.408']\n",
      "Epoch 30/30;  7s;  ['loss: 0.014', 'val_loss: 0.013', 'mean_abs_err: 0.088', 'val_mean_abs_err: 0.086', 'r2: 0.314', 'val_r2: 0.409']\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "metrics = ['mean_abs_err', 'r2']\n",
    "verbose = True\n",
    "fit_kwargs = {'epochs': epochs, 'device': device, 'verbose': verbose, 'metrics': metrics}\n",
    "\n",
    "logs = fit(model=model,\n",
    "           loss_fnc=loss_fnc,\n",
    "           opt=opt,\n",
    "           tr_dl=tr_loader,\n",
    "           vl_dl=vl_loader,\n",
    "           **fit_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "# plt.plot(logs['loss'], label='loss');\n",
    "# plt.plot(logs['val_loss'], label='val_loss');\n",
    "# plt.legend(loc='best');\n",
    "\n",
    "# plt.plot(logs['mean_abs_err'], label='mean_abs_err');\n",
    "# plt.plot(logs['val_mean_abs_err'], label='val_mean_abs_err');\n",
    "# plt.legend(loc='best');\n",
    "\n",
    "plt.plot(logs['r2'], label='r2');\n",
    "plt.plot(logs['val_r2'], label='val_r2');\n",
    "plt.legend(loc='best');\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit(model: nn.Module,\n",
    "#         loss_fnc,\n",
    "#         opt: torch.optim,\n",
    "#         tr_dl: torch.utils.data.DataLoader,\n",
    "#         vl_dl: torch.utils.data.DataLoader=None,\n",
    "#         epochs: int=1,\n",
    "#         device: torch.device='cuda:0',\n",
    "#         verbose: bool=True,\n",
    "#         metrics=[]) -> dict:\n",
    "#     \"\"\" github.com/stared/livelossplot/blob/master/examples/pytorch.ipynb\n",
    "#     Args:\n",
    "#         metrics (list) : list of metric scores to log\n",
    "#             (available metrics: 'mean_abs_err','median_abs_err', 'mean_sqrd_err', 'r2)\n",
    "#     \"\"\" \n",
    "#     print(f'Arg `device`: {device}')\n",
    "#     model.to(device)\n",
    "#     print('current_device:', torch.cuda.current_device())\n",
    "    \n",
    "#     # Choose cuda device with context manager --> try using context manager!!!\n",
    "#     # with torch.cuda.device(device):\n",
    "        \n",
    "#     # Create dicts to log scores\n",
    "#     if vl_dl is None:\n",
    "#         logs = OrderedDict({'loss': []})\n",
    "#         logs.update(OrderedDict({m: [] for m in metrics}))        \n",
    "#     else:\n",
    "#         logs = OrderedDict({'loss': [], 'val_loss': []})\n",
    "#         for m in metrics: logs.update(OrderedDict({m: [], 'val_'+m: []}))\n",
    "    \n",
    "#     # Iter over epochs\n",
    "#     phases = ['train', 'val'] if vl_dl is not None else ['train']\n",
    "#     for ep in range(epochs):\n",
    "#         ep_t0 = time()\n",
    "        \n",
    "#         # -------------\n",
    "#         # Training loop\n",
    "#         # -------------\n",
    "#         model.train() # turns-on dropout for training\n",
    "#         tr_scores = {m: 0 for m in logs.keys() if 'val' not in m}\n",
    "        \n",
    "#         for xx, yy in tr_dl:\n",
    "#             xx = xx.to(device)\n",
    "#             yy = yy.to(device)\n",
    "            \n",
    "#             # Process batch\n",
    "#             loss, pred = proc_batch(xx, yy, model, loss_fnc, opt=opt)\n",
    "                  \n",
    "#             # Compute metrics (running avg)\n",
    "#             tr_scores['loss'] += loss.item()\n",
    "#             tr_scores = update_scores_reg(pred=pred, true=yy, scores=tr_scores)\n",
    "                \n",
    "#         for m in tr_scores.keys():\n",
    "#             print(m)\n",
    "#             logs[m].append(tr_scores[m]/len(tr_dl))\n",
    "                \n",
    "#         del xx, yy, loss, pred, tr_scores\n",
    "                \n",
    "#         # ---------------\n",
    "#         # Validation loop\n",
    "#         # ---------------        \n",
    "#         if vl_dl is not None:\n",
    "#             model.eval()  # turn-off dropout in inferenece\n",
    "#             vl_scores = {m: 0 for m in logs.keys() if 'val' in m}\n",
    "            \n",
    "#             with torch.no_grad():\n",
    "#                 for xx, yy in vl_dl:\n",
    "#                     xx = xx.to(device)\n",
    "#                     yy = yy.to(device)\n",
    "                    \n",
    "#                     # Process batch\n",
    "#                     loss, pred = proc_batch(xx, yy, model, loss_fnc, opt=None)\n",
    "                                \n",
    "#                     # Compute metrics at the end of each epoch (not the running avg across the batches)\n",
    "#                     vl_scores['val_loss'] += loss.item()\n",
    "#                     vl_scores = update_scores_reg(pred=pred, true=yy, scores=vl_scores)\n",
    "                        \n",
    "#                 # Update logs\n",
    "#                 for m in vl_scores.keys():\n",
    "#                     print(m)\n",
    "#                     logs[m].append(vl_scores[m]/len(vl_dl))\n",
    "        \n",
    "#                 del xx, yy, loss, pred, vl_scores\n",
    "        \n",
    "#         if verbose:\n",
    "#             print(f'Epoch {ep+1}/{epochs}; ',\n",
    "#                   f'{int(time()-ep_t0)}s; ',\n",
    "#                   [f'{k}: {v[-1]:.3f}' for k, v in logs.items()])\n",
    "#     return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verbose = True\n",
    "# epochs = 10\n",
    "# logs = OrderedDict({'loss': [], 'val_loss': [],\n",
    "#                     'mean_abs_err': [], 'val_mean_abs_err': [],\n",
    "#                     'r2': [], 'val_r2': []})\n",
    "\n",
    "# # Choose cuda device with context manager\n",
    "# with torch.cuda.device(device):\n",
    "#     print('\\ncurrent_device:', torch.cuda.current_device())\n",
    "    \n",
    "#     for ep in range(epochs):\n",
    "#         ep_t0 = time()\n",
    "        \n",
    "#         # -------------\n",
    "#         # Training loop\n",
    "#         # -------------\n",
    "#         model.train() # turns-on dropout for training\n",
    "#         tr_loss, tr_mae, tr_r2 = 0, 0, 0\n",
    "\n",
    "#         for xx, yy in tr_loader:\n",
    "#             xx = xx.to(device) # move data to gpu/cpu device\n",
    "#             yy = yy.to(device) # move data to gpu/cpu device\n",
    "            \n",
    "#             # Feedforward\n",
    "#             pred = model(xx)\n",
    "#             loss = loss_fnc(pred, yy)\n",
    "\n",
    "#             # Backprop and optimization\n",
    "#             opt.zero_grad()\n",
    "#             loss.backward()   # compute loss gradients wrt to model parameters and inputs\n",
    "#             opt.step()  # update model parameters;  pytorch.org/docs/stable/optim.html\n",
    "            \n",
    "#             # Compute metrics\n",
    "#             tr_loss += loss.item() # item() returns a number from a tensor that contains a single value\n",
    "#             tr_mae += torch.mean(torch.abs(pred-yy))\n",
    "#             tr_r2 += r2_torch(y_true=yy, y_pred=pred)\n",
    "\n",
    "#         tr_loss /= len(tr_loader)\n",
    "#         tr_mae /= len(tr_loader)\n",
    "#         tr_r2 /= len(tr_loader)\n",
    "        \n",
    "#         logs['loss'].append(tr_loss)\n",
    "#         logs['mae'].append(tr_mae)\n",
    "#         logs['r2'].append(tr_r2)\n",
    "\n",
    "#         del xx, yy\n",
    "\n",
    "#         # ---------------\n",
    "#         # Validation loop\n",
    "#         # ---------------\n",
    "#         if vl_loader is not None:\n",
    "#             model.eval()  # turn-off dropout in inferenece\n",
    "#             with torch.no_grad():\n",
    "#                 vl_loss, vl_mae, vl_r2 = 0, 0, 0\n",
    "\n",
    "#                 for xx, yy in vl_loader:\n",
    "#                     xx = xx.to(device)\n",
    "#                     yy = yy.to(device)\n",
    "\n",
    "#                     # Feedforward\n",
    "#                     pred = model(xx)\n",
    "#                     loss = loss_fnc(pred, yy)\n",
    "\n",
    "#                     # Compute metrics\n",
    "#                     vl_loss += loss.item() # item() returns a number from a tensor that contains a single value\n",
    "#                     vl_mae += torch.mean(torch.abs(pred-yy))\n",
    "#                     vl_r2 += r2_torch(y_true=yy, y_pred=pred)\n",
    "\n",
    "#                 vl_loss /= len(vl_loader)\n",
    "#                 vl_mae /= len(vl_loader)\n",
    "#                 vl_r2 /= len(vl_loader)\n",
    "\n",
    "#                 logs['val_loss'].append(vl_loss)\n",
    "#                 logs['val_mae'].append(vl_mae)\n",
    "#                 logs['val_r2'].append(vl_r2)\n",
    "\n",
    "#                 del xx, yy\n",
    "\n",
    "# #         if verbose:\n",
    "# #             print(f'Epoch {ep+1}/{epochs}; ',\n",
    "# #                   f'{int(time()-t0)}s; '\n",
    "# #                   f'tr_loss: {tr_loss:.3f}; ',\n",
    "# #                   f'vl_loss: {vl_loss:.3f}; ',\n",
    "# #                   f'tr_mae: {tr_mae:.3f}; ',\n",
    "# #                   f'vl_mae: {vl_mae:.3f}; ',\n",
    "# #                   f'tr_r2: {tr_r2:.3f}; ',\n",
    "# #                   f'vl_r2: {vl_r2:.3f}; ')\n",
    "            \n",
    "#         if verbose:\n",
    "#             print(f'Epoch {ep+1}/{epochs}; ',\n",
    "#                   f'{int(time()-ep_t0)}s; ',\n",
    "#                   [f'{k}: {v[-1]:.3f}' for k, v in logs.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:p1_] *",
   "language": "python",
   "name": "conda-env-p1_-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
